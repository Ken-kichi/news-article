# LangGraphã§ä½œã‚‹è‡ªå‹•ãƒ‹ãƒ¥ãƒ¼ã‚¹å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼šè¨˜äº‹ã‹ã‚‰å‹•ç”»ç”Ÿæˆã¾ã§ã‚’è‡ªå‹•åŒ–

_Markdownã§æ›¸ã„ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹åŸç¨¿ã‚’ã€éŸ³å£°ãƒ»æ˜ åƒãƒ»ã‚µãƒ ãƒã‚¤ãƒ«ãƒ»YouTubeæŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã¾ã§ä¸€æ°—ã«é‡ç”£ã™ã‚‹ LangGraph ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®è¨­è¨ˆã¨å®Ÿè£…ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚Azure/OpenAI ã‚¹ã‚¿ãƒƒã‚¯ã¨MoviePyã‚’æ´»ç”¨ã—ã€ã€Œæ¯æ—¥ã®è¨˜äº‹ã‚’æ¯æ—¥ã®å‹•ç”»ã«å¤‰æ›ã™ã‚‹ã€å®Ÿé‹ç”¨ãƒ¬ãƒ™ãƒ«ã®è‡ªå‹•åŒ–æ‰‹é †ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚_

## ã¯ã˜ã‚ã«

ã€Œæ¯æ—¥æ›¸ã„ã¦ã„ã‚‹ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’å‹•ç”»ã«ã§ããŸã‚‰ã€ã‚‚ã£ã¨å¤šãã®äººã«å±Šã‘ã‚‰ã‚Œã‚‹ã®ã«â€¦ã€

ãã‚“ãªæ€ã„ã‹ã‚‰ã€ã“ã®è‡ªå‹•å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚LangGraphã‚’ä½¿ã£ã¦è¨˜äº‹ã®è¦ç´„ã‹ã‚‰ç”»åƒç”Ÿæˆã€éŸ³å£°åˆæˆã€å‹•ç”»ç·¨é›†ã¾ã§ã‚’ä¸€è²«ã—ã¦è‡ªå‹•åŒ–ã™ã‚‹ã“ã¨ã§ã€è¨˜äº‹åŸ·ç­†è€…ãŒæ–°ãŸãªè¦–è´è€…å±¤ã¸ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã™ã‚‹æ‰‹æ®µã‚’æä¾›ã—ã¾ã™ã€‚

æœ¬è¨˜äº‹ã§ã¯ã€å®Ÿéš›ã«ç¨¼åƒã—ã¦ã„ã‚‹è‡ªå‹•å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å…¨å®¹ã‚’ã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã¨ã¨ã‚‚ã«è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ä¸€ã¤ã²ã¨ã¤ã®å½¹å‰²ã‚„è¨­è¨ˆæ€æƒ³ã¾ã§è¸ã¿è¾¼ã‚“ã§èª¬æ˜ã™ã‚‹ã®ã§ã€ã‚ãªãŸè‡ªèº«ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚‚ã™ãã«å¿œç”¨ã§ãã‚‹ã¯ãšã§ã™ã€‚

## ã“ã®è¨˜äº‹ã§å­¦ã¹ã‚‹ã“ã¨

ã“ã®è¨˜äº‹ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã®å®Ÿè·µçš„ãªã‚¹ã‚­ãƒ«ã¨çŸ¥è­˜ãŒèº«ã«ã¤ãã¾ã™ã€‚

LangGraphã«ã‚ˆã‚‹è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­è¨ˆã§ã¯ã€çŠ¶æ…‹ç®¡ç†ã¨ãƒãƒ¼ãƒ‰è¨­è¨ˆã®å®Ÿè·µçš„ãªæ‰‹æ³•ã‚’ç¿’å¾—ã§ãã¾ã™ã€‚Azure AIã‚µãƒ¼ãƒ“ã‚¹ã®çµ±åˆæ´»ç”¨ã§ã¯ã€GPT-4ã€FLUXç”»åƒç”Ÿæˆã€éŸ³å£°åˆæˆã®é€£æºæ–¹æ³•ã‚’å­¦ã¹ã¾ã™ã€‚å‹•ç”»ç”Ÿæˆã®å®Ÿè£…ãƒã‚¦ãƒã‚¦ã§ã¯ã€MoviePyã‚’ä½¿ã£ãŸå‹•ç”»ç·¨é›†ã®è‡ªå‹•åŒ–æŠ€è¡“ã‚’èº«ã«ã¤ã‘ã‚‰ã‚Œã¾ã™ã€‚ãã—ã¦ã€ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®å·¥å¤«ã¨ã—ã¦ã€æ–™é‡‘æœ€é©åŒ–ã‚„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å®Ÿä¾‹ã‚’ç†è§£ã§ãã¾ã™ã€‚

## âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ©ç”¨ã™ã‚‹å‰ã«ã€å¿…ãšç†è§£ã—ã¦ãŠãã¹ãé‡è¦ãªãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã™ã€‚æœŸå¾…å€¤ã®èª¿æ•´ã¨ã€é‹ç”¨ä¸Šã®ãƒªã‚¹ã‚¯ç®¡ç†ã®ãŸã‚ã«ã€ä»¥ä¸‹ã®å†…å®¹ã‚’å¿…ãšãŠèª­ã¿ãã ã•ã„ã€‚

### ç”Ÿæˆã•ã‚Œã‚‹å‹•ç”»ã®ç¯„å›²

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•ç”Ÿæˆã™ã‚‹ã‚‚ã®ã¯ç´ æå‹•ç”»ã§ã™ã€‚ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã€è¨˜äº‹ã«é–¢é€£ã—ãŸç”»åƒã€ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã¨ã®çµ„ã¿åˆã‚ã›ã€åŸºæœ¬çš„ãªå‹•ç”»ã‚¯ãƒªãƒƒãƒ—ã‚’çµåˆã—ã¦ã„ã¾ã™ã€‚

ä¸€æ–¹ã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ç”Ÿæˆã•ã‚Œãšã€æ‰‹å‹•ç·¨é›†ãŒå¿…è¦ãªã‚‚ã®ã¯ã€å­—å¹•ãƒ»ãƒ†ãƒ­ãƒƒãƒ—ã€BGMï¼ˆèƒŒæ™¯éŸ³æ¥½ï¼‰ã€SEï¼ˆåŠ¹æœéŸ³ï¼‰ã€ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°æ˜ åƒã€ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æ˜ åƒã€ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³åŠ¹æœã§ã™ã€‚

è¦–è´è€…ã«å…¬é–‹ã§ãã‚‹å®Œæˆå“ã«ã™ã‚‹ã«ã¯ã€Canvaãªã©ã®å‹•ç”»ç·¨é›†ãƒ„ãƒ¼ãƒ«ã§ã®è¿½åŠ ç·¨é›†ãŒå¿…é ˆã¨ãªã‚Šã¾ã™ã€‚

### ãã®ä»–ã®é‡è¦ãªæ³¨æ„ç‚¹

é‹ç”¨ã‚’é–‹å§‹ã™ã‚‹å‰ã«ã€ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦ã‚‚ååˆ†ã«ç†è§£ã—ã€æº–å‚™ã‚’æ•´ãˆã¦ãã ã•ã„ã€‚

#### 1. è‘—ä½œæ¨©ãƒ»è‚–åƒæ¨©ã¸ã®é…æ…®

ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã®é¸å®šã§ã¯ã€å¿…ãšå•†ç”¨åˆ©ç”¨å¯èƒ½ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ç´ æã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ç”Ÿæˆç”»åƒã®ç¢ºèªã§ã¯ã€FLUXã§ç”Ÿæˆã•ã‚ŒãŸç”»åƒã«å®Ÿåœ¨ã®äººç‰©ã‚„è‘—ä½œç‰©ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ã€å¿…ãšç›®è¦–ç¢ºèªãŒå¿…è¦ã§ã™ã€‚è¨˜äº‹ã®å¼•ç”¨å…ƒã«ã¤ã„ã¦ã¯ã€å…ƒè¨˜äº‹ãŒä»–ã‚µã‚¤ãƒˆã‹ã‚‰ã®å¼•ç”¨ã®å ´åˆã€å‹•ç”»åŒ–ã®è¨±è«¾ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚

#### 2. Azureã‚µãƒ¼ãƒ“ã‚¹ã®æ–™é‡‘ä½“ç³»

Azureã¯å¾“é‡èª²é‡‘åˆ¶ã§ã™ã€‚ä½¿ç”¨ã—ãŸåˆ†ã ã‘èª²é‡‘ã•ã‚Œã‚‹ãŸã‚ã€å¤§é‡ã®è¨˜äº‹ã‚’ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ã¨æƒ³å®šå¤–ã®ã‚³ã‚¹ãƒˆãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚Azure AIã‚µãƒ¼ãƒ“ã‚¹ã«ã¯ç„¡æ–™æ ãŒã‚ã‚Šã¾ã™ãŒã€ä¸Šé™ã‚’è¶…ãˆã‚‹ã¨è‡ªå‹•çš„ã«èª²é‡‘ãŒé–‹å§‹ã•ã‚Œã¾ã™ã€‚æœ¬æ ¼é‹ç”¨å‰ã«ã€1é€±é–“åˆ†ç¨‹åº¦ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã§ã‚³ã‚¹ãƒˆã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

#### 3. ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã®å³å®ˆ

è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§å‘½åã—ã¦ãã ã•ã„ã€‚

```
YYYYMMDD_ã‚¿ã‚¤ãƒˆãƒ«.md
```

ä¾‹ï¼š`20260214_AIæŠ€è¡“ã®æœ€æ–°å‹•å‘.md`

ã“ã®è¦å‰‡ã‚’å®ˆã‚‰ãªã„ã¨ã€ã‚·ã‚¹ãƒ†ãƒ ãŒè¨˜äº‹ã‚’èªè­˜ã§ãã¾ã›ã‚“ã€‚

#### 4. å‹•ç”»ã®é•·ã•ã®åˆ¶é™

ç”Ÿæˆã•ã‚Œã‚‹å‹•ç”»ã¯60ç§’ã«åˆ¶é™ã—ã¦ã„ã¾ã™ã€‚è¤‡æ•°è¨˜äº‹ã‚’1ã¤ã®å‹•ç”»ã«ã¾ã¨ã‚ã‚‹å ´åˆã€å„è¨˜äº‹ã®è¦ç´„ãŒçŸ­ããªã‚Šã™ããªã„ã‚ˆã†ã€è¨˜äº‹æ•°ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚ç›®å®‰ã¨ã—ã¦ã€3ã€œ5è¨˜äº‹ç¨‹åº¦ãŒ1æœ¬ã®å‹•ç”»ã«é©ã—ã¦ã„ã¾ã™ã€‚

#### 5. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†

`output/`ãƒ•ã‚©ãƒ«ãƒ€ã¯å®Ÿè¡Œã®ãŸã³ã«å¤§é‡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚å®šæœŸçš„ãªæ•´ç†ãŒå¿…è¦ã§ã™ï¼ˆç‰¹ã«WAVãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ï¼‰ã€‚æœ¬ç•ªç’°å¢ƒã§ã¯ã€å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å‰Šé™¤ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è¿½åŠ ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

#### 6. å‡¦ç†æ™‚é–“ã«ã¤ã„ã¦

1è¨˜äº‹ã‚ãŸã‚Šã®å‡¦ç†æ™‚é–“ã®ç›®å®‰ã¯ã€è¦ç´„ç”ŸæˆãŒ10ã€œ20ç§’ã€éŸ³å£°ç”ŸæˆãŒ10ã€œ15ç§’ã€ç”»åƒç”ŸæˆãŒ20ã€œ30ç§’ã€å‹•ç”»åˆæˆãŒè¨˜äº‹ã®é•·ã•ã«ä¾å­˜ï¼ˆ1åˆ†ã®å‹•ç”»ã§ç´„30ã€œ60ç§’ï¼‰ã§ã™ã€‚åˆè¨ˆã§ã€5è¨˜äº‹ã®å ´åˆã¯ç´„5ã€œ10åˆ†ç¨‹åº¦ã®å‡¦ç†æ™‚é–“ãŒå¿…è¦ã§ã™ã€‚

#### 7. ã‚¨ãƒ©ãƒ¼æ™‚ã®å¯¾å¿œ

ã‚·ã‚¹ãƒ†ãƒ ãŒã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ãŸå ´åˆã¯ã€`output/*/node_logs.jsonl`ã§ã©ã®ãƒãƒ¼ãƒ‰ã§å¤±æ•—ã—ãŸã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚Azureã®ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’ç¢ºèªã—ï¼ˆéšœå®³ãŒç™ºç”Ÿã—ã¦ã„ãªã„ã‹ï¼‰ã€APIã‚­ãƒ¼ã‚„æ¥ç¶šæƒ…å ±ãŒæ­£ã—ã„ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ç‰¹å®šã®è¨˜äº‹ã®ã¿ã‚’é™¤å¤–ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

## ãªãœã“ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ãŸã®ã‹

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºèƒŒæ™¯ã«ã¯ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ãŒç›´é¢ã™ã‚‹ç¾å®Ÿçš„ãªèª²é¡ŒãŒã‚ã‚Šã¾ã—ãŸã€‚ã“ã“ã§ã¯ã€ãã®èª²é¡Œã¨è§£æ±ºã¸ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èª¬æ˜ã—ã¾ã™ã€‚

### èƒŒæ™¯ã«ã‚ã£ãŸ3ã¤ã®èª²é¡Œ

éŸ³å£°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦ã®æ´»ç”¨ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã—ãŸã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬è¨˜äº‹ã‚’å®¶äº‹ã‚„é€šå‹¤ä¸­ã«éŸ³å£°ã§èããŸã„ã¨ã„ã†ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚Šã¾ã—ãŸãŒã€æ¯æ—¥æ‰‹ä½œæ¥­ã§éŸ³å£°åŒ–ã™ã‚‹ã®ã¯ç¾å®Ÿçš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚

æ–°ã—ã„è¦–è´è€…å±¤ã¸ã®ãƒªãƒ¼ãƒã‚‚é‡è¦ãªèª²é¡Œã§ã—ãŸã€‚ãƒ†ã‚­ã‚¹ãƒˆè¨˜äº‹ã ã‘ã§ã¯å±Šã‹ãªã„ã€Œå‹•ç”»ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦‹ã‚‹å±¤ã€ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã—ãŸã„ã¨ã„ã†ç‹™ã„ãŒã‚ã‚Šã¾ã—ãŸã€‚YouTube Shortsã¯ç‰¹ã«è‹¥ã„ä¸–ä»£ã«å¼·ã„å½±éŸ¿åŠ›ãŒã‚ã‚Šã¾ã™ã€‚

ãã—ã¦ã€LangGraphã®å®Ÿè·µçš„ãªå­¦ç¿’ã¨ã„ã†æŠ€è¡“çš„ãªå‹•æ©Ÿã‚‚ã‚ã‚Šã¾ã—ãŸã€‚LangGraphã¯é€šå¸¸ã€æ–‡ç« ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ãŒã€ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢ç”Ÿæˆã¨ã„ã†æ–°ã—ã„ç”¨é€”ã«æŒ‘æˆ¦ã—ã¦ã¿ãŸã‹ã£ãŸã®ã§ã™ã€‚

## ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€6ã¤ã®LangGraphãƒãƒ¼ãƒ‰ãŒç›´åˆ—ã«ã¤ãªãŒã‚‹ã“ã¨ã§ã€Œè¨˜äº‹ â†’ éŸ³å£° â†’ ç”»åƒ â†’ ã‚µãƒ ãƒã‚¤ãƒ« â†’ å‹•ç”» â†’ YouTubeãƒ¡ã‚¿æƒ…å ±ã€ã¨ã„ã†ä¸€é€£ã®ç”Ÿæˆå‡¦ç†ã‚’è‡ªå‹•åŒ–ã—ã¦ã„ã¾ã™ã€‚å„ãƒãƒ¼ãƒ‰ã¯å˜ä¸€è²¬å‹™ã§è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€éšœå®³èª¿æŸ»ã‚„å€‹åˆ¥ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒã—ã‚„ã™ã„æ§‹é€ ã«ãªã£ã¦ã„ã¾ã™ã€‚

### å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å…¨ä½“åƒ

```mermaid
flowchart TD
    Articles[(article/*.md)] --> Fetch[fetch_articles<br/>è¨˜äº‹è¦ç´„]
    Fetch --> Audio[generate_audio_assets<br/>éŸ³å£°+SBVå­—å¹•]
    Audio --> Visual[generate_visual_assets<br/>ç¸¦é•·ã‚¤ãƒ©ã‚¹ãƒˆ]
    Visual --> Thumb[generate_thumbnail<br/>16:9ã‚µãƒ ãƒ]
    Thumb --> Video[create_video<br/>MoviePyç·¨é›†]
    Video --> Meta[generate_youtube_metadata<br/>ã‚¿ã‚¤ãƒˆãƒ«/æ¦‚è¦/ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°]
    Meta --> Outputs[(output/YYYYMMDD_*)]
    Outputs --> Canva
    Canva --> YouTube

    style Fetch fill:#e1f5ff,stroke:#5b9bd5
    style Audio fill:#fff9e1,stroke:#f6c343
    style Visual fill:#ffe1f5,stroke:#d246a3
    style Thumb fill:#e8e1ff,stroke:#7a5af5
    style Video fill:#e1ffe7,stroke:#2eb67d
    style Meta fill:#f5e1ff,stroke:#b453b6
    style Outputs fill:#f0f0f0,stroke:#888
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant CLI as CLI (Typer)
    participant Fetch as fetch_articles
    participant Audio as generate_audio_assets
    participant Visual as generate_visual_assets
    participant Thumb as generate_thumbnail
    participant Video as create_video
    participant Meta as generate_youtube_metadata

    CLI->>Fetch: generate 20260209 20260213
    Fetch->>Fetch: Markdownèª­ã¿è¾¼ã¿ãƒ»è¦ç´„
    Fetch-->>Audio: articles / summaries
    Audio->>Audio: Azure Speechã§audio_*.wav+script_*.sbv
    Audio-->>Visual: AgentStateæ›´æ–°
    Visual->>Visual: GPTâ†’FLUXã§image_*.png
    Visual-->>Thumb: image_pathsã‚’å…±æœ‰
    Thumb->>Thumb: youtube_thumbnail_*.pngç”Ÿæˆ
    Thumb-->>Video: thumbnail_pathã‚’æ›´æ–°
    Video->>Video: MoviePyã§final_youtube_short.mp4
    Video-->>Meta: å‹•ç”»ãƒ‘ã‚¹ãƒ»audio_timeline
    Meta->>Meta: youtube_meta.txt (ã‚¿ã‚¤ãƒˆãƒ«/èª¬æ˜/ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°)
    Meta-->>CLI: ç”Ÿæˆç‰©ãƒ‘ã‚¹ã‚’å‡ºåŠ›
```
### å‡¦ç†ãƒ•ãƒ­ãƒ¼
```mermaid
sequenceDiagram
    GPT4-->>LangGraph: ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿

    par ä¸¦åˆ—å‡¦ç†
        LangGraph->>AzureTTS: éŸ³å£°ç”Ÿæˆ
        AzureTTS-->>LangGraph: WAVãƒ•ã‚¡ã‚¤ãƒ«
    and
        LangGraph->>GPT4: ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        GPT4-->>LangGraph: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        LangGraph->>FLUX: ç”»åƒç”Ÿæˆ
        FLUX-->>LangGraph: PNGãƒ•ã‚¡ã‚¤ãƒ«
    end

    LangGraph->>MoviePy: ç´ æçµ±åˆ
    MoviePy-->>LangGraph: ç´ æå‹•ç”»
    LangGraph-->>User: ç´ æå‹•ç”»ï¼ˆç·¨é›†å‰ï¼‰

    Note over User: Canvaã§å­—å¹•ãƒ»BGMãƒ»SEè¿½åŠ 
    User->>User: YouTube Shorts å®Œæˆ
```

## é–‹ç™ºéç¨‹ã§ç›´é¢ã—ãŸèª²é¡Œã¨è§£æ±ºç­–

å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºã§ã¯ã€å¤šãã®è©¦è¡ŒéŒ¯èª¤ãŒã‚ã‚Šã¾ã—ãŸã€‚ã“ã“ã§ã¯ã€ä¸»è¦ãªèª²é¡Œã¨ãã®è§£æ±ºç­–ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ã§ã€ã‚ãªãŸãŒåŒã˜å•é¡Œã«ç›´é¢ã—ãŸã¨ãã®å‚è€ƒã«ãªã‚Œã°ã¨æ€ã„ã¾ã™ã€‚

### 1. å‹•ç”»ã®å˜èª¿ã•å¯¾ç­–

æœ€åˆã¯å„è¨˜äº‹1æšã®ç”Ÿæˆç”»åƒã®ã¿ã§å‹•ç”»ã‚’ä½œæˆã—ã¦ã„ã¾ã—ãŸãŒã€1åˆ†é–“åŒã˜ç”»åƒãŒè¡¨ç¤ºã•ã‚Œç¶šã‘ã‚‹ã®ã¯è¦–è´ä½“é¨“ã¨ã—ã¦é€€å±ˆã§ã—ãŸã€‚

è§£æ±ºç­–ã¨ã—ã¦ã€ç”Ÿæˆç”»åƒã‚’å†’é ­5ç§’ã®ã¿ä½¿ç”¨ã—ã€ãƒ•ãƒªãƒ¼ç´ æã®å‹•ç”»ã‚¯ãƒªãƒƒãƒ—ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æŒ¿å…¥ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ã‚ºãƒ¼ãƒ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã§é™æ­¢ç”»ã«å‹•ãã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚

```python
# ã‚ºãƒ¼ãƒ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®å®Ÿè£…ä¾‹
def zoom_factor(t, total=duration):
    return 1 + 0.05 * (t / max(total, 0.001))

base_image = base_image.with_effects([Resize(new_size=zoom_factor)])
```

ã“ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã€æ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«ç”»åƒãŒå¾ã€…ã«æ‹¡å¤§ã•ã‚Œã¾ã™ã€‚`zoom_factor`é–¢æ•°ã¯ã€æ™‚åˆ»`t`ã«ãŠã‘ã‚‹æ‹¡å¤§ç‡ã‚’è¨ˆç®—ã—ã€å…ƒã®ã‚µã‚¤ã‚ºã‹ã‚‰æœ€å¤§5%ã¾ã§æ‹¡å¤§ã—ã¾ã™ã€‚ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹ãŸã‚ã€`max(total, 0.001)`ã§æœ€å°å€¤ã‚’ä¿è¨¼ã—ã¦ã„ã¾ã™ã€‚

### 2. å­—å¹•ã®æŠ€è¡“çš„åˆ¶ç´„

å½“åˆã¯å‹•ç”»ã«è‡ªå‹•ã§å­—å¹•ã‚’å…¥ã‚Œã‚‹äºˆå®šã§ã—ãŸãŒã€ä½¿ç”¨ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ—¥æœ¬èªã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚

è§£æ±ºç­–ã¨ã—ã¦ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã¯å­—å¹•ãªã—å‹•ç”»ã‚’ç”Ÿæˆã—ã€Canvaãªã©ã®å‹•ç”»ç·¨é›†ãƒ„ãƒ¼ãƒ«ã§æ‰‹å‹•ã§å­—å¹•ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è‡ªå‹•ç”Ÿæˆã—ã€ç·¨é›†ä½œæ¥­ã‚’åŠ¹ç‡åŒ–ã—ã¦ã„ã¾ã™ã€‚

ã“ã®åˆ¶ç´„ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œå¾Œã¯å¿…ãšæ‰‹å‹•ã§ã®ç·¨é›†å·¥ç¨‹ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚å®Œå…¨è‡ªå‹•åŒ–ã‚’æœŸå¾…ã—ã¦ã„ãŸå ´åˆã¯ã€ã“ã®ç‚¹ã«ã”æ³¨æ„ãã ã•ã„ã€‚

### 3. ã‚³ã‚¹ãƒˆæœ€é©åŒ–

å„è¨˜äº‹ã”ã¨ã«AIå‹•ç”»ç”Ÿæˆï¼ˆRunwayã€Pikaãªã©ï¼‰ã‚’ä½¿ã†ã¨ã€æ–™é‡‘ãŒé«˜é¡ã«ãªã‚Šã™ãã¾ã—ãŸã€‚

è§£æ±ºç­–ã¨ã—ã¦ã€AIå‹•ç”»ç”Ÿæˆã‹ã‚‰é™æ­¢ç”»åƒç”Ÿæˆï¼ˆFLUXï¼‰ã¸å¤‰æ›´ã—ã€ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã¨ã®çµ„ã¿åˆã‚ã›ã§å‹•ãã‚’ç¢ºä¿ã—ã¾ã—ãŸã€‚ã“ã®å¤‰æ›´ã«ã‚ˆã‚Šã€æœˆé–“ã‚³ã‚¹ãƒˆã‚’ç´„1/10ã«å‰Šæ¸›ã§ãã¾ã—ãŸã€‚

### 4. ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å“è³ªã®å‘ä¸Š

è¨˜äº‹ã®å†’é ­500æ–‡å­—ã‚’ãã®ã¾ã¾èª­ã¿ä¸Šã’ã‚‹ã¨ã€URLã‚„ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¾ã§èª­ã¿ä¸Šã’ã¦ã—ã¾ã„ã€ä¸è‡ªç„¶ãªãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ãªã‚Šã¾ã—ãŸã€‚

è§£æ±ºç­–ã¨ã—ã¦ã€GPT-4ã«ã‚ˆã‚‹è¦ç´„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ ã—ã€URLãƒ»è¨˜å·ã®é™¤å»ã¨è‡ªç„¶ãªè©±ã—è¨€è‘‰ã¸ã®å¤‰æ›ã‚’æ˜ç¤ºçš„ã«æŒ‡ç¤ºã—ã¾ã—ãŸã€‚500æ–‡å­—ä»¥å†…ã®åˆ¶ç´„ã§ç°¡æ½”ãªåŸç¨¿ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚

## å®Ÿè£…ã‚¬ã‚¤ãƒ‰

ã“ã“ã‹ã‚‰ã€å®Ÿéš›ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¦ã„ãã¾ã™ã€‚å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¸å¯§ã«èª¬æ˜ã™ã‚‹ã®ã§ã€åˆã‚ã¦ã®æ–¹ã§ã‚‚ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚Œã‚‹ã¯ãšã§ã™ã€‚

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã¾ãšã¯ã€é–‹ç™ºç’°å¢ƒã®æº–å‚™ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®éª¨æ ¼ã‚’ä½œã‚Šã¾ã™ã€‚

#### 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ

```bash
mkdir news-article
cd news-article
uv init
uv venv
uv add azure-cognitiveservices-speech dotenv langchain langgraph openai langchain_openai moviepy typer
mkdir article movie output
touch config.py state.py nodes.py graph.py main.py
```

ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã®æ„å‘³ã‚’ç†è§£ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚`article/`ã«ã¯å¤‰æ›å…ƒã®è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`YYYYMMDD_ã‚¿ã‚¤ãƒˆãƒ«.md`å½¢å¼ï¼‰ã‚’é…ç½®ã—ã¾ã™ã€‚`movie/`ã«ã¯ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã‚’é…ç½®ã—ã¾ã™ã€‚`output/`ã«ã¯ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ»éŸ³å£°ãƒ»ç”»åƒãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚

#### 2. Azure AIã‚µãƒ¼ãƒ“ã‚¹ã®æº–å‚™

Azure AI Foundryã§ã€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’East USã«è¨­å®šã—ã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚

`FLUX.1-Kontext-pro`ï¼ˆç”»åƒç”Ÿæˆï¼‰ã¨`gpt-4.1`ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼‰ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ãã ã•ã„ã€‚

Azure Speech Serviceã§ã¯ã€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’East USã«è¨­å®šã—ã€éŸ³å£°ã¯`ja-JP-NanamiNeural`ï¼ˆè‡ªç„¶ãªæ—¥æœ¬èªå¥³æ€§éŸ³å£°ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://learn.microsoft.com/ja-jp/azure/ai-services/speech-service/get-started-text-to-speech)ã‚’å‚è€ƒã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

#### 3. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

```txt
# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
AZURE_TEXT_API_KEY=
AZURE_TEXT_ENDPOINT=

# éŸ³å£°
AZURE_SPEECH_KEY=
AZURE_SPEECH_ENDPOINT=
AZURE_SPEECH_REGION=

# ç”»åƒç”Ÿæˆ
AZURE_IMAGE_KEY=
AZURE_IMAGE_ENDPOINT=
```

å„å¤‰æ•°ã«ã¯ã€Azureãƒãƒ¼ã‚¿ãƒ«ã‹ã‚‰å–å¾—ã—ãŸAPIã‚­ãƒ¼ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

## ã‚³ã‚¢å®Ÿè£…

ã‚·ã‚¹ãƒ†ãƒ ã®å¿ƒè‡“éƒ¨ã¨ãªã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¦ã„ãã¾ã™ã€‚å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²ã¨ã€ã‚³ãƒ¼ãƒ‰ã®è©³ç´°ãªè§£èª¬ã‚’è¡Œã„ã¾ã™ã€‚

### config.pyï¼ˆè¨­å®šç®¡ç†ï¼‰

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹è¨­å®šå€¤ã‚’ä¸€å…ƒç®¡ç†ã—ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å€¤ã‚’èª­ã¿è¾¼ã¿ã€å‹å®‰å…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```python
import os
from dotenv import load_dotenv

load_dotenv()


def _split_endpoint(endpoint: str | None) -> tuple[str | None, str | None]:
    """ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã‹ã‚‰ãƒ™ãƒ¼ã‚¹URLã¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŠ½å‡ºã™ã‚‹ã€‚

    Azure OpenAIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯é€šå¸¸ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå½¢å¼ã§ã™ï¼š
    https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=2024-02-01

    ã“ã®é–¢æ•°ã¯ã€ä¸Šè¨˜URLã‹ã‚‰ä»¥ä¸‹ã‚’æŠ½å‡ºã—ã¾ã™ï¼š
    - ãƒ™ãƒ¼ã‚¹URL: https://your-resource.openai.azure.com/
    - APIãƒãƒ¼ã‚¸ãƒ§ãƒ³: 2024-02-01

    Args:
        endpoint: Azure OpenAIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL

    Returns:
        (ãƒ™ãƒ¼ã‚¹URL, APIãƒãƒ¼ã‚¸ãƒ§ãƒ³)ã®ã‚¿ãƒ—ãƒ«ã€‚ã©ã¡ã‚‰ã‚‚Noneã®å ´åˆã‚ã‚Šã€‚
    """
    if not endpoint:
        return None, None

    base = endpoint.strip()
    if not base:
        return None, None

    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰api-versionã‚’æŠ½å‡º
    api_version = None
    if "api-version=" in base:
        api_version = base.split("api-version=")[-1].split("&")[0].strip()

    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤å»
    base = base.split("?")[0]

    # /openai/ä»¥é™ã®ãƒ‘ã‚¹ã‚’é™¤å»ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåãªã©ã‚’å«ã‚€éƒ¨åˆ†ï¼‰
    if "/openai/" in base:
        base = base.split("/openai/")[0]

    # æœ«å°¾ã«/ã‚’è¿½åŠ ã—ã¦æ­£è¦åŒ–
    normalized = base.rstrip("/") + "/"
    return normalized, api_version


# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç”Ÿã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
_raw_text_endpoint = os.getenv("AZURE_TEXT_ENDPOINT")
_text_endpoint, _text_version = _split_endpoint(_raw_text_endpoint)

_raw_image_endpoint = os.getenv("AZURE_IMAGE_ENDPOINT")
_image_endpoint, _image_version = _split_endpoint(_raw_image_endpoint)


class Config:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚

    ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å€¤ã‚’ã€å‹å®‰å…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹å½¢ã§æä¾›ã—ã¾ã™ã€‚
    ã“ã®ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã€ã©ã“ã‹ã‚‰ã§ã‚‚è¨­å®šå€¤ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚
    """

    # Azure OpenAIï¼ˆãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ï¼‰ã®è¨­å®š
    AZURE_TEXT_API_KEY = os.getenv("AZURE_TEXT_API_KEY")
    AZURE_TEXT_ENDPOINT = _text_endpoint
    AZURE_TEXT_API_VERSION = os.getenv("AZURE_TEXT_API_VERSION", _text_version or "2024-02-01-preview")
    AZURE_OPENAI_DEPLOYMENT_NAME = "gpt-4.1"

    # Azure AI Speechï¼ˆéŸ³å£°åˆæˆç”¨ï¼‰ã®è¨­å®š
    AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")
    AZURE_SPEECH_ENDPOINT = os.getenv("AZURE_SPEECH_ENDPOINT")
    AZURE_SPEECH_REGION = os.getenv("AZURE_SPEECH_REGION")

    # Azure AIï¼ˆç”»åƒç”Ÿæˆç”¨ï¼‰ã®è¨­å®š
    AZURE_IMAGE_API_KEY = os.getenv("AZURE_IMAGE_KEY")
    AZURE_IMAGE_ENDPOINT = _image_endpoint
    AZURE_IMAGE_API_VERSION = os.getenv("AZURE_IMAGE_API_VERSION", _image_version or "2023-12-01-preview")
    AZURE_IMAGE_DEVELOPMENT_NAME = "FLUX.1-Kontext-pro"

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š
    ARTICLE_DIR = "./article"  # è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    OUTPUT_DIR = "./output"    # ç”Ÿæˆç‰©ã‚’å‡ºåŠ›ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    JP_FONT_PATH = os.getenv("JP_FONT_PATH")  # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ãƒ‘ã‚¹ï¼ˆå°†æ¥ã®å­—å¹•ç”Ÿæˆç”¨ï¼‰
    MOVIE_DIR = "./movie"      # ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã‚’é…ç½®ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
```

ã“ã®ã‚³ãƒ¼ãƒ‰ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ã€`_split_endpoint`é–¢æ•°ã§ã™ã€‚Azureã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯è¤‡é›‘ãªå½¢å¼ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ã€ã“ã®é–¢æ•°ã§ãƒ™ãƒ¼ã‚¹URLã¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ­£è¦åŒ–ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¾Œç¶šã®ã‚³ãƒ¼ãƒ‰ã§ã‚·ãƒ³ãƒ—ãƒ«ã«Azure APIã‚’å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

`Config`ã‚¯ãƒ©ã‚¹ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹è¨­å®šå€¤ã‚’ä¸€ç®‡æ‰€ã«é›†ç´„ã—ã¾ã™ã€‚æ–°ã—ã„è¨­å®šãŒå¿…è¦ã«ãªã£ãŸã¨ãã‚‚ã€ã“ã®ã‚¯ãƒ©ã‚¹ã«è¿½åŠ ã™ã‚‹ã ã‘ã§æ¸ˆã¿ã¾ã™ã€‚

### state.pyï¼ˆçŠ¶æ…‹å®šç¾©ï¼‰

LangGraphã§ã¯ã€ãƒãƒ¼ãƒ‰é–“ã§å—ã‘æ¸¡ã™ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’æ˜ç¢ºã«å®šç¾©ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹çŠ¶æ…‹ã‚’å‹å®‰å…¨ã«ç®¡ç†ã—ã¾ã™ã€‚

```python
from typing import TypedDict


class ArticleData(TypedDict):
    title: str
    display_title: str
    content: str
    date: str


class AgentState(TypedDict):
    start_date: str
    end_date: str
    run_output_dir: str
    single_article_path: str | None
    articles: list[ArticleData]
    audio_paths: list[str]
    image_paths: list[str]
    script_paths: list[str]
    thumbnail_path: str | None
    video_path: str | None
    youtube_metadata_path: str | None
    error: str | None


```

`TypedDict`ã‚’ä½¿ã†ã“ã¨ã§ã€Pythonã®å‹ãƒã‚§ãƒƒã‚«ãƒ¼ï¼ˆmypyã€Pylanceãªã©ï¼‰ãŒçŠ¶æ…‹ã®æ§‹é€ ã‚’ç†è§£ã—ã€è£œå®Œã‚„å‹ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡ºã‚’è¡Œãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¤§è¦æ¨¡ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã‚‚ãƒã‚°ã‚’æœªç„¶ã«é˜²ã’ã¾ã™ã€‚

`AgentState`ã®è¨­è¨ˆæ€æƒ³ã¯ã€ã€Œå„ãƒãƒ¼ãƒ‰ãŒå¿…è¦ãªæƒ…å ±ã ã‘ã‚’èª­ã¿å–ã‚Šã€è‡ªåˆ†ã®å‡¦ç†çµæœã ã‘ã‚’è¿½åŠ ã™ã‚‹ã€ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ¼ãƒ‰é–“ã®ä¾å­˜é–¢ä¿‚ãŒæ˜ç¢ºã«ãªã‚Šã€ä¸¦åˆ—åŒ–ã‚„å†å®Ÿè¡ŒãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚

### nodes.pyï¼ˆå‡¦ç†ãƒãƒ¼ãƒ‰å®Ÿè£…ï¼‰

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚·ã‚¹ãƒ†ãƒ ã®å¿ƒè‡“éƒ¨ã§ã™ã€‚è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã‹ã‚‰å‹•ç”»ç”Ÿæˆã¾ã§ã€ã™ã¹ã¦ã®å‡¦ç†ã‚’å®Ÿè£…ã—ã¾ã™ã€‚å„é–¢æ•°ã®å½¹å‰²ã¨ãƒ­ã‚¸ãƒƒã‚¯ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

```python
import base64
import json
import os
import random
import re
from datetime import datetime
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from moviepy.video.VideoClip import ImageClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.audio.AudioClip import concatenate_audioclips
from moviepy.video.compositing.CompositeVideoClip import concatenate_videoclips
from moviepy.video.fx.Resize import Resize
from moviepy.video.io.VideoFileClip import VideoFileClip
from config import Config
from state import AgentState


def _log_node_output(run_dir: str, node_name: str, payload: dict):
    """Append a JSON line containing node metadata to the current run directory."""
    os.makedirs(run_dir, exist_ok=True)
    log_path = os.path.join(run_dir, "node_logs.jsonl")
    entry = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "node": node_name,
        "payload": payload
    }
    with open(log_path, "a", encoding="utf-8") as log_file:
        json.dump(entry, log_file, ensure_ascii=False)
        log_file.write("\n")


def _extract_title_from_content(raw_content: str, fallback: str) -> str:
    """Return the first non-empty line from raw markdown as a human friendly title."""
    for line in raw_content.splitlines():
        candidate = line.strip().lstrip("#").strip()
        if candidate:
            return candidate[:120]
    return fallback


text_client = AzureOpenAI(
    api_key=Config.AZURE_TEXT_API_KEY,
    api_version=Config.AZURE_TEXT_API_VERSION,
    azure_endpoint=Config.AZURE_TEXT_ENDPOINT,
    azure_deployment=Config.AZURE_OPENAI_DEPLOYMENT_NAME,
)

image_client = AzureOpenAI(
    api_key=Config.AZURE_IMAGE_API_KEY,
    api_version=Config.AZURE_IMAGE_API_VERSION,
    azure_endpoint=Config.AZURE_IMAGE_ENDPOINT,
    azure_deployment=Config.AZURE_IMAGE_DEVELOPMENT_NAME,
)

VIDEO_EXTENSIONS = (".mp4", ".mov", ".m4v", ".avi", ".webm", ".mkv")


def _list_movie_files() -> list[str]:
    """Collect usable background video files from the configured movie directory."""
    movie_dir = Config.MOVIE_DIR
    if not movie_dir or not os.path.isdir(movie_dir):
        return []
    files = []
    for name in os.listdir(movie_dir):
        if name.lower().endswith(VIDEO_EXTENSIONS):
            files.append(os.path.join(movie_dir, name))
    return files


def _format_date_label(date_str: str) -> str:
    """Convert YYYYMMDD into YYYY/MM/DD for display."""
    try:
        return datetime.strptime(date_str, "%Y%m%d").strftime("%Y/%m/%d")
    except ValueError:
        return date_str


def _format_date_range_label(start: str, end: str) -> str:
    """Create a human-friendly date range label."""
    start_label = _format_date_label(start)
    end_label = _format_date_label(end)
    return start_label if start == end else f"{start_label} - {end_label}"


def _clean_hashtag_text(text: str) -> str:
    """Normalize text so it can sit behind a YouTube hashtag."""
    cleaned = re.sub(r"[#ï¼ƒ]", "", text)
    cleaned = re.sub(r"\s+", "", cleaned)
    cleaned = re.sub(r"[^\wã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯ãƒ¼]+", "", cleaned)
    return cleaned[:20].strip()


def _extract_hashtags(articles: list[dict]) -> list[str]:
    """Build a short list of hashtags derived from article titles."""
    hashtags: list[str] = []
    for article in articles:
        candidate = article.get('display_title') or article.get('title')
        if not candidate:
            continue
        cleaned = _clean_hashtag_text(candidate)
        if not cleaned or cleaned in hashtags:
            continue
        hashtags.append(cleaned)
        if len(hashtags) >= 5:
            break

    for fallback in ("ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»", "AIé€Ÿå ±"):
        if len(hashtags) >= 5:
            break
        if fallback not in hashtags:
            hashtags.append(fallback)

    return hashtags[:5]


def _generate_youtube_metadata(state: AgentState) -> dict:
    """Compose a YouTube-ready title, description, and hashtags from the run state."""
    articles = state.get('articles', [])
    range_label = _format_date_range_label(
        state['start_date'], state['end_date'])

    if articles:
        title = f"{range_label}ã®ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹TOP{len(articles)} | ã‚·ãƒ§ãƒ¼ãƒˆè§£èª¬"
        if len(articles) == 1:
            title = f"{range_label} {articles[0]['title'] } | ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚·ãƒ§ãƒ¼ãƒˆ"
    else:
        title = f"{range_label}ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ"

    description_lines = [
        f"ğŸ“… åéŒ²æœŸé–“: {range_label}",
        "",
        "ğŸ“ å–ã‚Šä¸Šã’ãŸãƒˆãƒ”ãƒƒã‚¯:"
    ]
    if articles:
        for article in articles:
            description_lines.append(
                f"- {article.get('display_title') or article['title']} ({_format_date_label(article.get('date', state['start_date']))})"
            )
    else:
        description_lines.append("- è©²å½“ã™ã‚‹è¨˜äº‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    description = "\n".join(description_lines).strip()
    hashtags = _extract_hashtags(articles)

    return {
        "title": title,
        "description": description,
        "hashtags": hashtags
    }


def _format_timestamp(seconds: float) -> str:
    """Return SBV timestamp (H:MM:SS.mmm)."""
    milliseconds = max(0, int(round(seconds * 1000)))
    hours, remainder = divmod(milliseconds, 3600 * 1000)
    minutes, remainder = divmod(remainder, 60 * 1000)
    secs, millis = divmod(remainder, 1000)
    return f"{hours}:{minutes:02}:{secs:02}.{millis:03}"


def _split_sentences_for_captions(text: str) -> list[str]:
    """Split narration text into SBV-friendly chunks."""
    if not text:
        return []

    stripped = text.strip()
    if not stripped:
        return []

    # ã€Œã€‚ã€ã§ã®ã¿åŒºåˆ‡ã‚Šã€å¥èª­ç‚¹ã‚’ç¶­æŒã—ãŸã¾ã¾æŠ½å‡º
    sentences = [
        chunk.strip()
        for chunk in re.findall(r'[^ã€‚]+ã€‚?', stripped)
        if chunk.strip()
    ]

    return sentences or [stripped]


def _build_sbv_caption(text: str, duration: float | None) -> str:
    """Generate SBV caption text with pseudo-timed segments."""
    sentences = _split_sentences_for_captions(text)
    if not sentences:
        sentences = ["ï¼ˆå†…å®¹ãªã—ï¼‰"]

    total_chars = sum(len(s) for s in sentences) or 1
    total_duration = duration if duration and duration > 0 else len(
        sentences) * 3.0

    raw_durations = []
    for sentence in sentences:
        portion = max(0.8, (len(sentence) / total_chars) * total_duration)
        raw_durations.append(portion)

    scale = total_duration / \
        sum(raw_durations) if sum(raw_durations) > 0 else 1.0
    durations = [d * scale for d in raw_durations]

    lines = []
    cursor = 0.0
    for sentence, seg_duration in zip(sentences, durations):
        start_ts = _format_timestamp(cursor)
        end_ts = _format_timestamp(cursor + seg_duration)
        lines.append(f"{start_ts},{end_ts}")
        lines.append(sentence)
        lines.append("")
        cursor += seg_duration

    return "\n".join(lines).strip() + "\n"


def fetch_articles_node(state: AgentState):
    """Load dated markdown articles in range and summarize them for narration."""
    target_articles = []
    start = datetime.strptime(state['start_date'], "%Y%m%d")
    end = datetime.strptime(state['end_date'], "%Y%m%d")
    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR

    single_article_path = state.get("single_article_path")

    if not single_article_path and not os.path.exists(Config.ARTICLE_DIR):
        os.makedirs(Config.ARTICLE_DIR)

    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    files_to_process: list[tuple[str, str, str]] = []
    if single_article_path:
        if not os.path.isfile(single_article_path):
            raise FileNotFoundError(f"è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {single_article_path}")
        basename = os.path.basename(single_article_path)
        match = re.match(r"(\d{8})_(.*)\.md", basename)
        if match:
            file_date_str, title = match.groups()
        else:
            file_date_str = state['start_date']
            title = os.path.splitext(basename)[0]
        files_to_process.append((single_article_path, title, file_date_str))
    else:
        for filename in os.listdir(Config.ARTICLE_DIR):
            match = re.match(r"(\d{8})_(.*)\.md", filename)
            if match:
                file_date_str, title = match.groups()
                file_date = datetime.strptime(file_date_str, "%Y%m%d")
                if start <= file_date <= end:
                    files_to_process.append(
                        (os.path.join(Config.ARTICLE_DIR, filename), title, file_date_str))

    # 2. å„è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã¨è¦ç´„ï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ä½œæˆï¼‰
    for filepath, title, date_str in files_to_process:
        with open(filepath, 'r', encoding='utf-8') as f:
            raw_content = f.read()

        # GPT-4oã«ã‚ˆã‚‹è¦ç´„ã¨ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•´å½¢
        # ã“ã“ã§URLã®é™¤å»ã‚„è‡ªç„¶ãªè¨€ã„å›ã—ã¸ã®å¤‰æ›ã‚’æŒ‡ç¤º
        response = text_client.chat.completions.create(
            model=Config.AZURE_OPENAI_DEPLOYMENT_NAME,  # GPT-4oç”¨ãƒ‡ãƒ—ãƒ­ã‚¤å
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ã§ã™ã€‚"},
                {"role": "user", "content": f"""
ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ã€YouTubeã‚·ãƒ§ãƒ¼ãƒˆç”¨ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã€åˆ¶ç´„äº‹é …ã€‘
ãƒ»500æ–‡å­—ä»¥å†…
ãƒ»å†’é ­15ç§’ï¼ˆç´„60æ–‡å­—ï¼‰ã§æ ¸å¿ƒã‚’ä¼ãˆã‚‹ï¼šã€Œä½•ãŒèµ·ããŸã®ã‹ã€ã€Œãªãœé‡è¦ãªã®ã‹ã€ã‚’æœ€åˆã«æ˜ç¤º
ãƒ»ãã®å¾Œã€æ™‚ç³»åˆ—ã‚„å› æœé–¢ä¿‚ã«æ²¿ã£ã¦èƒŒæ™¯ãƒ»çµŒç·¯ãƒ»å½±éŸ¿ã‚’ç°¡æ½”ã«èª¬æ˜
ãƒ»URLã‚„è¨˜å·ï¼ˆ[ ]ã€( )ãªã©ï¼‰ã¯å®Œå…¨ã«å‰Šé™¤ã¾ãŸã¯è‡ªç„¶ãªè¨€è‘‰ã«ç½®ãæ›ãˆã‚‹
ãƒ»å°‚é–€ç”¨èªã¯ä½¿ç”¨å¯ï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³å‘ã‘ï¼‰ã ãŒã€å¿…è¦ã«å¿œã˜ã¦ç°¡æ½”ãªè£œè¶³ã‚’å…¥ã‚Œã‚‹
ãƒ»ã§ã™ãƒ»ã¾ã™èª¿ã§çµ±ä¸€ã—ã€é å›ã—ãªè¡¨ç¾ã¯é¿ã‘ã‚‹
ãƒ»ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ã‚„å®Ÿå‹™çš„ãªæ„å‘³ã‚’å„ªå…ˆçš„ã«å«ã‚ã‚‹

è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {title}
è¨˜äº‹å†…å®¹:
{raw_content}
"""}
            ]
        )

        summarized_content = response.choices[0].message.content.strip()
        human_title = _extract_title_from_content(
            raw_content, title.replace("_", " "))

        target_articles.append({
            'title': title,
            'display_title': human_title,
            'content': summarized_content,  # ã“ã“ã«ç¶ºéº—ãªè¦ç´„ãŒå…¥ã‚‹
            'date': date_str
        })
        print(f"âœ… è¦ç´„å®Œäº†: {title}")

    _log_node_output(
        run_dir,
        "fetch_articles",
        {
            "article_count": len(target_articles),
            "article_titles": [article['display_title'] for article in target_articles],
            "articles": target_articles
        }
    )

    return {'articles': target_articles, 'run_output_dir': run_dir}


def generate_audio_assets_node(state: AgentState):
    """Create narration audio files and scripts for each article."""
    audio_paths = []
    script_paths = []
    voice_outputs = []

    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)

    for i, article in enumerate(state['articles']):
        # å„è¨˜äº‹ã”ã¨ã« Azure Speech ã‚’è¨­å®šï¼ˆéŸ³å£°ã‚¹ã‚¿ã‚¤ãƒ«ã‚’çµ±ä¸€ï¼‰
        speech_config = speechsdk.SpeechConfig(
            subscription=Config.AZURE_SPEECH_KEY,
            region=Config.AZURE_SPEECH_REGION
        )
        speech_config.speech_synthesis_voice_name = "ja-JP-NanamiNeural"

        audio_filename = f"audio_{i}.wav"
        audio_path = os.path.join(run_dir, audio_filename)
        audio_config = speechsdk.audio.AudioOutputConfig(filename=audio_path)

        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’éŸ³å£°åŒ–ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜
        synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=speech_config, audio_config=audio_config)
        synthesizer.speak_text_async(article['content']).get()
        audio_paths.append(audio_path)

        # å­—å¹•ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨ˆç®—ç”¨ã«é•·ã•ã‚’å–å¾—ï¼ˆå¤±æ•—ã—ã¦ã‚‚ç„¡è¦–ï¼‰
        audio_duration = None
        try:
            temp_clip = AudioFileClip(audio_path)
            audio_duration = temp_clip.duration or None
        except Exception:
            audio_duration = None
        finally:
            try:
                temp_clip.close()
            except Exception:
                pass

        script_filename = f"script_{i}.sbv"
        script_path = os.path.join(run_dir, script_filename)
        # SBV å½¢å¼ã®å­—å¹•ã‚’ç”Ÿæˆã—ã€YouTubeã§ç›´æ¥ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
        captions_content = _build_sbv_caption(
            article['content'], audio_duration)
        with open(script_path, "w", encoding="utf-8") as script_file:
            script_file.write(captions_content)
        script_paths.append(script_path)

        voice_outputs.append({
            "index": i,
            "article_title": article.get('display_title') or article['title'],
            "audio_path": audio_path,
            "script_path": script_path,
            "spoken_text": article['content']
        })

    _log_node_output(
        run_dir,
        "generate_audio_assets",
        {
            "audio_files": [os.path.basename(p) for p in audio_paths],
            "script_files": [os.path.basename(p) for p in script_paths],
            "voice_outputs": [
                {
                    "index": entry["index"],
                    "article_title": entry["article_title"],
                    "spoken_text": entry["spoken_text"],
                    "audio_file": os.path.basename(entry["audio_path"]),
                    "script_file": os.path.basename(entry["script_path"])
                }
                for entry in voice_outputs
            ]
        }
    )

    return {
        'audio_paths': audio_paths,
        'script_paths': script_paths,
        'run_output_dir': run_dir
    }


def generate_visual_assets_node(state: AgentState):
    """Create illustrative prompts and images for each article."""
    image_paths = []
    image_prompts = []
    image_outputs = []

    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)

    for i, article in enumerate(state['articles']):
        # GPT ã«æ˜ ç”»çš„ãªé¢¨æ™¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œã‚‰ã›ã‚‹ï¼ˆFLUXç”¨ï¼‰
        prompt_response = text_client.chat.completions.create(
            model=Config.AZURE_OPENAI_DEPLOYMENT_NAME,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ã‚ãªãŸã¯å ±é“ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’èª­ã¿ã€"
                        "ãã®å†…å®¹ã‚’è¦–è¦šçš„ã«ä¼ãˆã‚‹ç”»åƒç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‹±èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"

                        "ã€å¿…é ˆè¦ç´ ã€‘\n"
                        "ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ ¸å¿ƒçš„ãªã€Œãƒ¢ãƒã€ã€Œå ´æ‰€ã€ã€ŒçŠ¶æ³ã€ã‚’å…·ä½“çš„ã«æå†™\n"
                        "ãƒ»æŠ€è¡“ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šè£½å“ã€ãƒ‡ãƒã‚¤ã‚¹ã€ã‚¤ãƒ³ãƒ•ãƒ©ã€ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n"
                        "ãƒ»ãƒ“ã‚¸ãƒã‚¹ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šã‚ªãƒ•ã‚£ã‚¹ç©ºé–“ã€éƒ½å¸‚æ™¯è¦³ã€ä¼æ¥­ãƒ­ã‚´ã®ãªã„ãƒ“ãƒ«ç¾¤\n"
                        "ãƒ»æ”¿ç­–ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šè­°å ´ã€å…¬å…±æ–½è¨­ã€è±¡å¾´çš„ãªå»ºé€ ç‰©\n"
                        "ãƒ»ç’°å¢ƒç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šè‡ªç„¶ç’°å¢ƒã€æ°—å€™ç¾è±¡ã€ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ \n\n"

                        "ã€ç¦æ­¢äº‹é …ã€‘\n"
                        "ãƒ»å®Ÿåœ¨ã®äººç‰©ã®é¡”ã‚„ä½“ï¼ˆå¾Œã‚å§¿ã‚„é æ™¯ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã¯å¯ï¼‰\n"
                        "ãƒ»å®Ÿåœ¨ä¼æ¥­ã®ãƒ­ã‚´ã‚„å•†æ¨™\n"
                        "ãƒ»ç‰¹å®šå¯èƒ½ãªå€‹äººãŒå†™ã‚Šè¾¼ã‚€æ§‹å›³\n\n"

                        "ã€æ¨å¥¨è¡¨ç¾ã€‘\n"
                        "ãƒ»æŠ½è±¡çš„ãªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ï¼ˆä¾‹ï¼šAIãƒ‹ãƒ¥ãƒ¼ã‚¹â†’è„³ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¨¡æ§˜ï¼‰\n"
                        "ãƒ»è±¡å¾´çš„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆä¾‹ï¼šåŠå°ä½“ãƒ‹ãƒ¥ãƒ¼ã‚¹â†’ãƒã‚¤ã‚¯ãƒ­ãƒãƒƒãƒ—ã®ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—ï¼‰\n"
                        "ãƒ»ç’°å¢ƒã‚„ç©ºé–“ã§çŠ¶æ³ã‚’è¡¨ç¾ï¼ˆä¾‹ï¼šçµŒæ¸ˆå±æ©Ÿâ†’ç„¡äººã®ã‚ªãƒ•ã‚£ã‚¹ãƒ•ãƒ­ã‚¢ï¼‰\n\n"

                        "ã€ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡å®šã€‘\n"
                        "ãƒ»9:16ç¸¦å‹æ§‹å›³ã‚’æ„è­˜\n"
                        "ãƒ»ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¸ãƒ£ãƒ¼ãƒŠãƒªã‚ºãƒ é¢¨ã®å†™å®Ÿçš„ã‚¹ã‚¿ã‚¤ãƒ«\n"
                        "ãƒ»è‰²å½©ã¯è¨˜äº‹ã®ãƒˆãƒ¼ãƒ³ï¼ˆå¸Œæœ›çš„/è­¦å‘Šçš„/ä¸­ç«‹çš„ï¼‰ã«åˆã‚ã›ã‚‹\n"
                        "ãƒ»è¦–èªæ€§ã®é«˜ã„æ˜ç­ãªæ§‹å›³"
                    )
                },
                {
                    "role": "user",
                    "content": f"è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {article.get('display_title') or article['title']}\nè¨˜äº‹å†…å®¹: {article['content']}"
                }
            ]
        )
        img_prompt = prompt_response.choices[0].message.content.strip()
        image_prompts.append(img_prompt)

        # 9:16 æ¯”ç‡ã®ã‚¤ãƒ©ã‚¹ãƒˆã‚’æç”»ã—ã€å‹•ç”»å†’é ­ã®é™æ­¢ç”»ã«ä½¿ç”¨
        image_result = image_client.images.generate(
            model=Config.AZURE_IMAGE_DEVELOPMENT_NAME,
            prompt=f"{img_prompt} Digital art style, vibrant colors, 9:16 aspect ratio focus.",
            size="1792x1024",
            n=1,
            response_format="b64_json",
        )

        image_data = image_result.data[0]
        image_location = None
        if image_data.url:
            image_location = image_data.url
            image_paths.append(image_location)
        else:
            image_filename = f"image_{i}.png"
            image_path = os.path.join(run_dir, image_filename)
            with open(image_path, "wb") as img_file:
                img_file.write(base64.b64decode(image_data.b64_json))
            image_location = image_path
            image_paths.append(image_location)

        image_outputs.append({
            "index": i,
            "article_title": article.get('display_title') or article['title'],
            "prompt": img_prompt,
            "image_path": image_location
        })

    _log_node_output(
        run_dir,
        "generate_visual_assets",
        {
            "image_files": [os.path.basename(p) if p else None for p in image_paths],
            "image_prompts": image_prompts,
            "image_outputs": [
                {
                    "index": entry["index"],
                    "article_title": entry["article_title"],
                    "prompt": entry["prompt"],
                    "image_file": os.path.basename(entry["image_path"]) if entry["image_path"] else None
                }
                for entry in image_outputs
            ]
        }
    )

    return {
        'image_paths': image_paths,
        'run_output_dir': run_dir
    }


def create_short_video_node(state: AgentState):
    """Combine generated images, stock footage, and narration into one short video."""
    clips = []
    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)
    output_path = os.path.join(run_dir, "final_youtube_short.mp4")
    movie_files = _list_movie_files()
    video_sources: list[VideoFileClip] = []
    article_visual_logs = []
    article_audio_clips: list[AudioFileClip] = []
    audio_timeline = []
    audio_cursor = 0.0

    for i, article in enumerate(state['articles']):
        audio = AudioFileClip(state['audio_paths'][i])
        article_audio_clips.append(audio)
        duration = audio.duration or 0
        duration = max(duration, 0.001)

        base_image = ImageClip(state['image_paths'][i], duration=duration)
        base_image = base_image.with_effects([Resize(height=1920)])

        def zoom_factor(t, total=duration):
            return 1 + 0.05 * (t / max(total, 0.001))

        base_image = base_image.with_effects([Resize(new_size=zoom_factor)])
        base_image = base_image.with_position("center")

        segments = []
        movie_segments_log = []

        image_intro_duration = min(5, duration)
        segments.append(base_image.with_duration(image_intro_duration))
        remaining = duration - image_intro_duration

        while remaining > 1e-3 and movie_files:
            movie_path = random.choice(movie_files)
            try:
                video_clip = VideoFileClip(movie_path)
                video_sources.append(video_clip)
            except Exception:
                continue

            clip_duration = min(5, remaining, video_clip.duration or 0)
            if clip_duration <= 0:
                video_clip.close()
                continue

            max_start = max(
                0, (video_clip.duration or clip_duration) - clip_duration)
            start = random.uniform(0, max_start) if max_start > 0 else 0

            segment = video_clip.subclipped(
                start_time=start,
                end_time=start + clip_duration
            ).with_audio(None)

            segment = segment.with_effects(
                [Resize(height=1920)]).with_position("center")
            segments.append(segment)

            movie_segments_log.append({
                "file": os.path.basename(movie_path),
                "start": round(start, 2),
                "duration": round(clip_duration, 2)
            })

            remaining -= clip_duration

        if remaining > 1e-3:
            segments.append(base_image.with_duration(remaining))

        article_video = concatenate_videoclips(
            segments, method="compose").with_duration(duration)
        article_video.audio = audio
        clips.append(article_video)

        article_visual_logs.append({
            "article": article.get('display_title') or article['title'],
            "movie_segments": movie_segments_log
        })

        audio_timeline.append({
            "article": article.get('display_title') or article['title'],
            "audio_file": os.path.basename(state['audio_paths'][i]),
            "start": round(audio_cursor, 2),
            "duration": round(duration, 2)
        })
        audio_cursor += duration

    final_video = concatenate_videoclips(clips, method="compose")
    final_audio = None
    if article_audio_clips:
        final_audio = concatenate_audioclips(article_audio_clips)
        final_video.audio = final_audio

    try:
        final_video.write_videofile(
            output_path, fps=24, codec="libx264", audio_codec="aac"
        )
    finally:
        final_video.close()
        if final_audio is not None:
            try:
                final_audio.close()
            except Exception:
                pass
        for audio_clip in article_audio_clips:
            try:
                audio_clip.close()
            except Exception:
                pass
        for source in video_sources:
            try:
                source.close()
            except Exception:
                pass

    _log_node_output(
        run_dir,
        "create_video",
        {
            "video_file": os.path.basename(output_path),
            "clip_count": len(clips),
            "articles": article_visual_logs,
            "audio_timeline": audio_timeline
        }
    )

    return {
        "video_path": output_path,
        'run_output_dir': run_dir
    }


def generate_youtube_metadata_node(state: AgentState):
    """Produce a YouTube-ready title, description, and hashtag set."""
    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)

    metadata = _generate_youtube_metadata(state)
    hashtags_line = " ".join(f"#{tag}" for tag in metadata['hashtags']).strip()
    metadata_path = os.path.join(run_dir, "youtube_meta.txt")

    articles = state.get("articles") or []
    if articles:
        primary_title = articles[0].get(
            'display_title') or articles[0].get('title') or "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    else:
        primary_title = "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    note_line = f"- note: {primary_title}"
    zenn_line = f"- zenn: {primary_title}"

    spoken_block = "\n\n".join(
        article.get('content', '').strip()
        for article in articles if article.get('content')
    ).strip()

    sections = [
        "ä»Šå›ã®è¨˜äº‹",
        note_line,
        zenn_line,
        "",
    ]

    if articles:
        for idx, article in enumerate(articles, start=1):
            title = article.get('display_title') or article.get(
                'title') or f"è¨˜äº‹{idx}"
            spoken = article.get('content', '').strip()
            sections.append(f"{idx}. {title}")
            if spoken:
                sections.append(spoken)
            sections.append("")
    elif spoken_block:
        sections.append(spoken_block)
        sections.append("")

    sections.extend([
        "ITç³»ã®æƒ…å ±ã‚’ç™ºä¿¡ã—ã¦ã„ã¾ã™ã€‚",
        "note",
        "https://note.com/kenquichi",
        "zenn",
        "https://zenn.dev/kenquichi",
        "",
        "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹è¬›åº§",
        "https://note.com/kenquichi/m/mc4926a77c1da",
        "",

        "\n".join(f"#{tag}" for tag in metadata['hashtags']) or "#ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    ])

    final_text = "\n".join(sections).rstrip() + "\n"

    with open(metadata_path, "w", encoding="utf-8") as meta_file:
        meta_file.write(final_text)

    _log_node_output(
        run_dir,
        "generate_youtube_metadata",
        {
            "metadata_file": os.path.basename(metadata_path),
            "title": metadata['title'],
            "description": metadata['description'],
            "hashtags": metadata['hashtags'],
            "hashtags_line": hashtags_line or "#ãƒ‹ãƒ¥ãƒ¼ã‚¹ #ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»",
            "thumbnail_file": os.path.basename(state.get('thumbnail_path')) if state.get('thumbnail_path') else None
        }
    )

    return {
        "youtube_metadata_path": metadata_path,
        'run_output_dir': run_dir
    }


```

ã“ã®ãƒãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®æ ¸ã¨ãªã‚‹å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚å„é–¢æ•°ã¯ç‹¬ç«‹ã—ã¦å‹•ä½œã—ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ä»–ã®ãƒãƒ¼ãƒ‰ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ã‚ˆã†è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚

### graph.pyï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ï¼‰

LangGraphã®çœŸéª¨é ‚ã§ã‚ã‚‹DAGï¼ˆæœ‰å‘éå·¡å›ã‚°ãƒ©ãƒ•ï¼‰ã®å®šç¾©ã‚’è¡Œã„ã¾ã™ã€‚ã“ã“ã§ã€å„ãƒãƒ¼ãƒ‰ã®å®Ÿè¡Œé †åºã¨ä¾å­˜é–¢ä¿‚ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ã¾ã™ã€‚

```python
from langgraph.graph import StateGraph, END
from state import AgentState
from nodes import (
    fetch_articles_node,
    generate_audio_assets_node,
    generate_visual_assets_node,
    create_short_video_node,
    generate_youtube_metadata_node,
)


def create_graph():
    workflow = StateGraph(AgentState)

    # ãƒãƒ¼ãƒ‰ã®ç™»éŒ²
    workflow.add_node("fetch_articles", fetch_articles_node)
    workflow.add_node("generate_audio_assets", generate_audio_assets_node)
    workflow.add_node("generate_visual_assets", generate_visual_assets_node)
    workflow.add_node("create_video", create_short_video_node)
    workflow.add_node("generate_youtube_metadata",
                      generate_youtube_metadata_node)

    # ã‚¨ãƒƒã‚¸ã®æ¥ç¶š
    workflow.set_entry_point("fetch_articles")
    workflow.add_edge("fetch_articles", "generate_audio_assets")
    workflow.add_edge("generate_audio_assets", "generate_visual_assets")
    workflow.add_edge("generate_visual_assets", "create_video")
    workflow.add_edge("create_video", "generate_youtube_metadata")
    workflow.add_edge("generate_youtube_metadata", END)

    return workflow.compile()


```

ã“ã®ã‚°ãƒ©ãƒ•å®šç¾©ã«ã‚ˆã‚Šã€å‡¦ç†ã®æµã‚ŒãŒæ˜ç¢ºã«ãªã‚Šã¾ã™ã€‚å°†æ¥çš„ã«ã€æ¡ä»¶åˆ†å²ï¼ˆä¾‹ï¼šè¨˜äº‹ãŒ0ä»¶ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰ã‚„ä¸¦åˆ—å‡¦ç†ï¼ˆä¾‹ï¼šéŸ³å£°ã¨ç”»åƒã‚’åŒæ™‚ç”Ÿæˆï¼‰ã‚’è¿½åŠ ã™ã‚‹å ´åˆã‚‚ã€ã“ã®ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’æ‹¡å¼µã™ã‚‹ã ã‘ã§å®Ÿç¾ã§ãã¾ã™ã€‚

LangGraphã®åˆ©ç‚¹ã¯ã€å„ãƒãƒ¼ãƒ‰ãŒç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ã€ç‰¹å®šã®ãƒãƒ¼ãƒ‰ã ã‘ã‚’ä¿®æ­£ã—ãŸã‚Šã€æ–°ã—ã„ãƒãƒ¼ãƒ‰ã‚’æŒ¿å…¥ã—ãŸã‚Šã™ã‚‹ã®ãŒå®¹æ˜“ãªç‚¹ã§ã™ã€‚

### main.pyï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰

ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚Typerã‚’ä½¿ç”¨ã—ã¦ã€ä½¿ã„ã‚„ã™ã„CLIã‚’æä¾›ã—ã¾ã™ã€‚

```python
import os
import re
from datetime import datetime
import typer
from typing import Annotated
from graph import create_graph
from state import AgentState
from config import Config


def _resolve_run_output_dir(base_path: str) -> str:
    """åŒåãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯æœ«å°¾ã« ver_n ã‚’ä»˜ã‘ã¦é‡è¤‡ã‚’é¿ã‘ã‚‹"""
    if not os.path.exists(base_path):
        return base_path

    version = 1
    while True:
        candidate = f"{base_path}_ver_{version}"
        if not os.path.exists(candidate):
            return candidate
        version += 1


def _extract_article_meta(article_path: str) -> tuple[str, str]:
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã¨ã‚¹ãƒ©ã‚°ã‚’å–å¾—ã€‚å½¢å¼å¤–ã®å ´åˆã¯å½“æ—¥ã®æ—¥ä»˜ã‚’åˆ©ç”¨ã€‚"""
    basename = os.path.basename(article_path)
    name_no_ext, _ = os.path.splitext(basename)
    match = re.match(r"(\d{8})_(.+)", name_no_ext)
    if match:
        return match.group(1), match.group(2)
    today = datetime.now().strftime("%Y%m%d")
    return today, name_no_ext or today


def _sanitize_slug(slug: str) -> str:
    cleaned = re.sub(r"[^\w\-]+", "_", slug)
    return cleaned.strip("_") or "article"


def _resolve_article_argument(article_arg: str) -> tuple[str, str | None]:
    """
    å¼•æ•°ãŒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãªã‚‰ãã®ã¾ã¾è¿”ã—ã€8æ¡ã®æ—¥ä»˜ãªã‚‰ article/ å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ç´¢ã—ã¦è¿”ã™ã€‚
    æˆ»ã‚Šå€¤ã¯ (çµ¶å¯¾ãƒ‘ã‚¹, æ¨å®šæ—¥ä»˜ or None)ã€‚
    """
    candidate_path = os.path.abspath(article_arg)
    if os.path.isfile(candidate_path):
        return candidate_path, None

    if not os.path.isabs(article_arg):
        relative_path = os.path.abspath(
            os.path.join(Config.ARTICLE_DIR, article_arg))
        if os.path.isfile(relative_path):
            return relative_path, None

    if re.match(r"^\d{8}$", article_arg):
        date_str = article_arg
        article_dir = Config.ARTICLE_DIR
        if not os.path.isdir(article_dir):
            raise typer.BadParameter("article ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        matches = [
            name for name in os.listdir(article_dir)
            if name.startswith(f"{date_str}_") and name.endswith(".md")
        ]
        if not matches:
            raise typer.BadParameter(f"{date_str} ã§å§‹ã¾ã‚‹è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        if len(matches) > 1:
            raise typer.BadParameter(
                f"{date_str} ã®è¨˜äº‹ãŒè¤‡æ•°ã‚ã‚Šã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )
        return os.path.abspath(os.path.join(article_dir, matches[0])), date_str

    raise typer.BadParameter("8æ¡ã®æ—¥ä»˜ã¾ãŸã¯è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")


app = typer.Typer()


@app.command()
def generate(
    start_date: Annotated[str, typer.Argument(help="é–‹å§‹æ—¥ (YYYYMMDD)")],
    end_date: Annotated[str, typer.Argument(help="çµ‚äº†æ—¥ (YYYYMMDD)")]
):
    """
    æŒ‡å®šã—ãŸæœŸé–“(YYYYMMDD)ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‹ã‚‰YouTubeã‚·ãƒ§ãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    typer.echo(f"ğŸš€ å‡¦ç†ã‚’é–‹å§‹: {start_date} ã‹ã‚‰ {end_date}")

    # ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ã¨ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
    graph = create_graph()

    # åˆå›ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    base_output_dir = os.path.join(
        Config.OUTPUT_DIR, f"{start_date}_{end_date}"
    )
    run_output_dir = _resolve_run_output_dir(base_output_dir)
    os.makedirs(run_output_dir, exist_ok=True)

    initial_state: AgentState = {
        "start_date": start_date,
        "end_date": end_date,
        "run_output_dir": run_output_dir,
        "single_article_path": None,
        "articles": [],
        "audio_paths": [],
        "image_paths": [],
        "script_paths": [],
        "thumbnail_path": None,
        "video_path": None,
        "youtube_metadata_path": None,
        "error": None
    }

    # LangGraphã®å®Ÿè¡Œ
    try:
        for output in graph.stream(initial_state):
            for node_name, state_update in output.items():
                typer.echo(f"âœ… Node [{node_name}] ãŒå®Œäº†ã—ã¾ã—ãŸ")

        typer.echo(f"âœ¨ å…¨å·¥ç¨‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼ output/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        typer.secho(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", fg=typer.colors.RED)


@app.command("generate-article")
def generate_single_article(
    article_identifier: Annotated[str, typer.Argument(help="è¨˜äº‹ã®8æ¡æ—¥ä»˜ã¾ãŸã¯è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")],
    date_override: Annotated[str | None, typer.Option(
        help="å‡ºåŠ›æ—¥æ™‚ (YYYYMMDD)ã€‚çœç•¥æ™‚ã¯è¨˜äº‹æƒ…å ±ã‹ã‚‰æ¨æ¸¬)")] = None,
):
    """
    å˜ä¸€ã®è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰YouTubeã‚·ãƒ§ãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    article_path, inferred_date = _resolve_article_argument(article_identifier)

    if date_override and not re.match(r"^\d{8}$", date_override):
        raise typer.BadParameter("date ã¯ YYYYMMDD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    date_from_file, slug = _extract_article_meta(article_path)
    date_str = date_override or inferred_date or date_from_file
    safe_slug = _sanitize_slug(slug)

    graph = create_graph()

    base_output_dir = os.path.join(
        Config.OUTPUT_DIR, f"{date_str}_{safe_slug}"
    )
    run_output_dir = _resolve_run_output_dir(base_output_dir)
    os.makedirs(run_output_dir, exist_ok=True)

    initial_state: AgentState = {
        "start_date": date_str,
        "end_date": date_str,
        "run_output_dir": run_output_dir,
        "single_article_path": article_path,
        "articles": [],
        "audio_paths": [],
        "image_paths": [],
        "script_paths": [],
        "thumbnail_path": None,
        "video_path": None,
        "youtube_metadata_path": None,
        "error": None
    }

    typer.echo(f"ğŸš€ å˜ä½“è¨˜äº‹ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ã‚’é–‹å§‹")
    try:
        for output in graph.stream(initial_state):
            for node_name, state_update in output.items():
                typer.echo(f"âœ… Node [{node_name}] ãŒå®Œäº†ã—ã¾ã—ãŸ")

        typer.echo(f"âœ¨ å®Œäº†: {run_output_dir} ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        typer.secho(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", fg=typer.colors.RED)


if __name__ == "__main__":
    app()


```

ã“ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã„ã‚„ã™ãã™ã‚‹ãŸã‚ã®å·¥å¤«ãŒè©°ã¾ã£ã¦ã„ã¾ã™ã€‚Typerã«ã‚ˆã‚‹å‹å®‰å…¨ãªCLIã€å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®é‡è¤‡å›é¿ã€é€²æ—ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºãªã©ã€å®Ÿç”¨çš„ãªæ©Ÿèƒ½ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

### å®Ÿè¡Œæ–¹æ³•

å®Ÿè£…ãŒå®Œäº†ã—ãŸã‚‰ã€å®Ÿéš›ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã“ã“ã§ã¯ã€å®Ÿè¡Œã«å¿…è¦ãªæº–å‚™ã¨ã€å®Ÿéš›ã®å®Ÿè¡Œæ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚

#### 1. ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã®æº–å‚™

`movie/`ãƒ•ã‚©ãƒ«ãƒ€ã«ã€è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼ã®å‹•ç”»ç´ æã‚’é…ç½®ã—ã¾ã™ã€‚

ãŠã™ã™ã‚ã®ç´ æã‚µã‚¤ãƒˆã¯ã€[Pexels Videos](https://www.pexels.com/videos/)ã€[Pixabay](https://pixabay.com/videos/)ã€[Videvo](https://www.videvo.net/)ã§ã™ã€‚

é‡è¦ãªã®ã¯ã€å¿…ãšå„ã‚µã‚¤ãƒˆã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ¡é …ã‚’ç¢ºèªã—ã€å•†ç”¨åˆ©ç”¨ãŒå¯èƒ½ãªã‚‚ã®ã‚’é¸ã¶ã“ã¨ã§ã™ã€‚

#### 2. è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½®

`article/`ãƒ•ã‚©ãƒ«ãƒ€ã«ã€ä»¥ä¸‹ã®å‘½åè¦å‰‡ã§è¨˜äº‹ã‚’é…ç½®ã—ã¾ã™ã€‚

```
20260212_AIã®æœ€æ–°å‹•å‘.md
20260213_é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®é€²åŒ–.md
20260214_å®‡å®™é–‹ç™ºãƒ‹ãƒ¥ãƒ¼ã‚¹.md
```

#### 3. å‹•ç”»ç”Ÿæˆã®å®Ÿè¡Œ

```bash
uv run main.py 20260212 20260214
```

å®Ÿè¡Œçµæœã®ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

```
ğŸš€ å‡¦ç†ã‚’é–‹å§‹: 20260212 ã‹ã‚‰ 20260214
âœ… è¦ç´„å®Œäº†: AIã®æœ€æ–°å‹•å‘
âœ… è¦ç´„å®Œäº†: é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®é€²åŒ–
âœ… è¦ç´„å®Œäº†: å®‡å®™é–‹ç™ºãƒ‹ãƒ¥ãƒ¼ã‚¹
âœ… Node [fetch_articles] ãŒå®Œäº†ã—ã¾ã—ãŸ
âœ… Node [generate_audio_assets] ãŒå®Œäº†ã—ã¾ã—ãŸ
âœ… Node [generate_visual_assets] ãŒå®Œäº†ã—ã¾ã—ãŸ
âœ… Node [generate_thumbnail] ãŒå®Œäº†ã—ã¾ã—ãŸ
âœ… Node [create_video] ãŒå®Œäº†ã—ã¾ã—ãŸ
âœ… Node [generate_youtube_metadata] ãŒå®Œäº†ã—ã¾ã—ãŸ
âœ¨ å…¨å·¥ç¨‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼ output/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
```

ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

`output/20260212_20260214/final_youtube_short.mp4`ï¼ˆç´ æå‹•ç”»ï¼‰ã€`output/20260212_20260214/audio_0.wav, audio_1.wav, ...`ã€`output/20260212_20260214/script_0.sbv, script_1.sbv, ...`ã€`output/20260212_20260214/image_0.png, image_1.png, ...`ã€`output/20260212_20260214/youtube_meta.txt`ã€`output/20260212_20260214/youtube_thumbnail_*.png`ã€`output/20260212_20260214/node_logs.jsonl`ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰

## ä»•ä¸Šã’ä½œæ¥­ï¼šCanvaã§ã®ç·¨é›†

ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ç”Ÿæˆã—ãŸå‹•ç”»ã¯ã€Œãƒ™ãƒ¼ã‚¹ç´ æã€ã§ã™ã€‚è¦–è´è€…ã«å…¬é–‹ã§ãã‚‹å®Œæˆå“ã«ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ç·¨é›†ä½œæ¥­ãŒå¿…é ˆã§ã™ã€‚ã“ã®å·¥ç¨‹ã‚’çµŒã‚‹ã“ã¨ã§ã€ç´ æå‹•ç”»ãŒé­…åŠ›çš„ãªYouTube Shortsã«å¤‰ã‚ã‚Šã¾ã™ã€‚

### ç·¨é›†ã§è¿½åŠ ã™ã‚‹è¦ç´ 

ç·¨é›†ã§è¿½åŠ ã™ã‚‹è¦ç´ ã¨ãã®ç›®çš„ã€æ¨å¥¨ãƒ„ãƒ¼ãƒ«ã‚’è¡¨ã«ã¾ã¨ã‚ã¾ã™ã€‚

å­—å¹•ãƒ»ãƒ†ãƒ­ãƒƒãƒ—ã¯è¦–è´è€…ã®ç†è§£ã‚’åŠ©ã‘ã‚‹ãŸã‚ã«å¿…è¦ã§ã€Canvaã€Vrewã€CapCutãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚BGMã¯å‹•ç”»ã®é›°å›²æ°—ã‚’ä½œã‚‹ãŸã‚ã«é‡è¦ã§ã€CanvaéŸ³æ¥½ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ArtlistãŒä¾¿åˆ©ã§ã™ã€‚SEï¼ˆåŠ¹æœéŸ³ï¼‰ã¯è¦–è´è€…ã®æ³¨æ„ã‚’å¼•ããŸã‚ã«ä½¿ç”¨ã—ã€Canvaã€Freesoundã§å…¥æ‰‹ã§ãã¾ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã¯ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å½¹ç«‹ã¡ã€Canvaãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ´»ç”¨ã§ãã¾ã™ã€‚ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã¯ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²èª˜å°ã®ãŸã‚ã«å¿…è¦ã§ã€Canvaãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚

### Canvaã§ã®ç·¨é›†æ‰‹é †

ç·¨é›†ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚åŠ¹ç‡çš„ã«ä½œæ¥­ã‚’é€²ã‚ã‚‹ãŸã‚ã®ãƒã‚¤ãƒ³ãƒˆã‚‚ç´¹ä»‹ã—ã¾ã™ã€‚

#### 1. Canvaã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

ç”Ÿæˆã—ãŸ`final_youtube_short.mp4`ã¨å„`script_*.sbv`ã‚’Canvaã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

#### 2. å­—å¹•ã®è¿½åŠ 

è‡ªå‹•å­—å¹•æ©Ÿèƒ½ã‚’ä½¿ã†å ´åˆã¯ã€å‹•ç”»ã‚’ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«é…ç½®ã—ã€ã€Œå­—å¹•ã‚’è¿½åŠ ã€â†’ã€Œè‡ªå‹•å­—å¹•ã€ã‚’é¸æŠã—ã¾ã™ã€‚æ—¥æœ¬èªã‚’é¸æŠã—ã¦ç”Ÿæˆã—ã€ç”Ÿæˆã•ã‚ŒãŸå­—å¹•ã‚’ç¢ºèªã—ã¦èª¤ã‚Šã‚’ä¿®æ­£ã—ã¾ã™ã€‚

æ‰‹å‹•ã§è¿½åŠ ã™ã‚‹å ´åˆã¯ã€`script_*.sbv`ã®å†…å®¹ã‚’å‚ç…§ã—ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¿½åŠ ã—ã¾ã™ã€‚éŸ³å£°ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«åˆã‚ã›ã¦é…ç½®ã—ã¦ãã ã•ã„ã€‚

å­—å¹•ãƒ‡ã‚¶ã‚¤ãƒ³ã®æ¨å¥¨è¨­å®šã¯ã€ãƒ•ã‚©ãƒ³ãƒˆã‚’ã‚´ã‚·ãƒƒã‚¯ä½“ï¼ˆæºãƒè§’ã‚´ã‚·ãƒƒã‚¯ã€Noto Sans JPãªã©ï¼‰ã€è‰²ã‚’ç™½æ–‡å­—ã€ç¸å–ã‚Šã‚’é»’ï¼ˆå¤ªã•ï¼šä¸­ã€œå¤ªï¼‰ã€ã‚µã‚¤ã‚ºã‚’ç”»é¢ã®1/5ã€œ1/6ç¨‹åº¦ã€ä½ç½®ã‚’ç”»é¢ä¸‹éƒ¨ï¼ˆãŸã ã—ã€YouTubeã®UIè¦ç´ ã¨é‡ãªã‚‰ãªã„ä½ç½®ï¼‰ã«è¨­å®šã™ã‚‹ã“ã¨ã§ã™ã€‚

#### 3. BGMã¨SEã®æŒ¿å…¥

BGMé¸å®šã®ãƒã‚¤ãƒ³ãƒˆã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®é›°å›²æ°—ã«åˆã£ãŸæ¥½æ›²ï¼ˆç·Šå¼µæ„Ÿã€å¸Œæœ›ã€å¥½å¥‡å¿ƒãªã©ï¼‰ã‚’é¸ã³ã€éŸ³é‡ã‚’ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é‚ªé­”ã—ãªã„ç¨‹åº¦ï¼ˆ-18dBã€œ-20dBç¨‹åº¦ï¼‰ã«è¨­å®šã™ã‚‹ã“ã¨ã§ã™ã€‚ãƒ«ãƒ¼ãƒ—ç´ æã‚’æ´»ç”¨ã—ã€å‹•ç”»ã®é•·ã•ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¾ã™ã€‚

SEï¼ˆåŠ¹æœéŸ³ï¼‰ã®æ´»ç”¨ä¾‹ã¨ã—ã¦ã€è¨˜äº‹ã®åˆ‡ã‚Šæ›¿ã‚ã‚Šæ™‚ã«ã€Œã‚·ãƒ¥ãƒƒã€ã¨ã„ã†é·ç§»éŸ³ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã§ã€Œãƒ”ã‚³ãƒ³ã€ã¨ã„ã†å¼·èª¿éŸ³ã€å‹•ç”»ã®é–‹å§‹æ™‚ã«ã€Œã‚¸ãƒ£ãƒ¼ãƒ³ã€ã¨ã„ã†ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆéŸ³ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

CanvaéŸ³æ¥½ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ´»ç”¨ã§ã¯ã€Canvaã«è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼ã®BGMãŒè±Šå¯Œã«ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã€Œãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã™ã‚‹ã¨ã€é©åˆ‡ãªæ¥½æ›²ãŒè¦‹ã¤ã‹ã‚Šã¾ã™ã€‚

#### 4. ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãƒ»ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã®è¿½åŠ 

ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ï¼ˆ2ã€œ3ç§’ï¼‰ã§ã¯ã€ãƒãƒ£ãƒ³ãƒãƒ«åã‚„ãƒ­ã‚´ã‚’è¡¨ç¤ºã—ã€ã€Œä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ãªã©ã®ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’å…¥ã‚Œã€ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ãªã‚‹åŠ¹æœéŸ³ã‚’è¿½åŠ ã—ã¾ã™ã€‚

ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ3ã€œ5ç§’ï¼‰ã§ã¯ã€ã€Œãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ãŠé¡˜ã„ã—ã¾ã™ã€ã¨è¡¨ç¤ºã—ã€SNSã®ãƒ•ã‚©ãƒ­ãƒ¼ãƒªãƒ³ã‚¯ã‚’æ²è¼‰ã—ã€æ¬¡å›äºˆå‘Šï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰ã‚’å…¥ã‚Œã¾ã™ã€‚

Canvaã«ã¯YouTubeå‘ã‘ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè±Šå¯Œã«ã‚ã‚‹ã®ã§ã€ãã‚Œã‚’æ´»ç”¨ã™ã‚‹ã¨åŠ¹ç‡çš„ã§ã™ã€‚

#### 5. æœ€çµ‚ãƒã‚§ãƒƒã‚¯é …ç›®

ç·¨é›†å®Œäº†å‰ã«ã€ä»¥ä¸‹ã®é …ç›®ã‚’å¿…ãšç¢ºèªã—ã¦ãã ã•ã„ã€‚

å­—å¹•ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯é©åˆ‡ã‹ï¼ˆéŸ³å£°ã¨ãšã‚Œã¦ã„ãªã„ã‹ï¼‰ã€å­—å¹•ã«èª¤å­—è„±å­—ã¯ãªã„ã‹ã€BGMã®éŸ³é‡ãƒãƒ©ãƒ³ã‚¹ã¯é©åˆ‡ã‹ï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒèãå–ã‚Œã‚‹ã‹ï¼‰ã€SEã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯è‡ªç„¶ã‹ã€å„è¨˜äº‹ã®å¢ƒç•ŒãŒæ˜ç¢ºã‹ï¼ˆè¦–è´è€…ãŒæ··ä¹±ã—ãªã„ã‹ï¼‰ã€å‹•ç”»ã®é•·ã•ã¯60ç§’ä»¥å†…ã‹ï¼ˆYouTube Shortsã®åˆ¶ç´„ï¼‰ã€ç¸¦å‹ï¼ˆ9:16ï¼‰ã§æ­£ã—ãè¡¨ç¤ºã•ã‚Œã‚‹ã‹ã€ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãƒ»ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã¯é©åˆ‡ãªé•·ã•ã‹ã€ç”Ÿæˆã•ã‚ŒãŸç”»åƒã«ä¸é©åˆ‡ãªå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ã€å…¨ä½“ã‚’é€šã—ã¦è¦–è´ã—ã¦é•å’Œæ„ŸãŒãªã„ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

## YouTubeã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆ¦ç•¥

å®Œæˆã—ãŸå‹•ç”»ã‚’åŠ¹æœçš„ã«YouTubeã«æŠ•ç¨¿ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’è§£èª¬ã—ã¾ã™ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚µãƒ ãƒã‚¤ãƒ«ã€èª¬æ˜æ¬„ã®æœ€é©åŒ–ãŒã€å‹•ç”»ã®å†ç”Ÿå›æ•°ã‚’å¤§ããå·¦å³ã—ã¾ã™ã€‚

### ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚µãƒ ãƒã‚¤ãƒ«

ã‚¿ã‚¤ãƒˆãƒ«ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

```
ã€60ç§’ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘AIãŒå¤‰ãˆã‚‹æœªæ¥ã®åƒãæ–¹ #ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ #AI
```

ãƒã‚¤ãƒ³ãƒˆã¯ã€å†’é ­ã«ã€ã€‘ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ˜ç¤ºã—ã€æ•°å­—ã§å…·ä½“æ€§ã‚’å‡ºã™ï¼ˆ60ç§’ã€3é¸ã€ãªã©ï¼‰ã“ã¨ã§ã™ã€‚ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã§æ¤œç´¢æ€§ã‚’å‘ä¸Šã•ã›ã€60æ–‡å­—ä»¥å†…ã«åã‚ã¾ã™ã€‚

ã‚µãƒ ãƒã‚¤ãƒ«ã¯ã€ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®ä¸­ã‹ã‚‰æœ€ã‚‚å°è±¡çš„ãªã‚‚ã®ã‚’é¸æŠã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã§è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ ã—ã¾ã™ã€‚é«˜ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã§è¦–èªæ€§ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚

### èª¬æ˜æ¬„ã®æœ€é©åŒ–

èª¬æ˜æ¬„ã®ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

```markdown
ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è©³ç´°ã¯ãƒ–ãƒ­ã‚°ã§ğŸ‘‡
https://example.com/blog/20260212

ã€ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ã€‘
ãƒ»AIã®æœ€æ–°å‹•å‘
ãƒ»é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®é€²åŒ–
ãƒ»å®‡å®™é–‹ç™ºãƒ‹ãƒ¥ãƒ¼ã‚¹

ğŸ”” æ¯æ—¥æ›´æ–°ä¸­ï¼ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ã§æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯

#ãƒ‹ãƒ¥ãƒ¼ã‚¹ #ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ #AI #é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿
```

èª¬æ˜æ¬„ã®ãƒã‚¤ãƒ³ãƒˆã¯ã€æœ€åˆã®3è¡ŒãŒé‡è¦ï¼ˆæŠ˜ã‚ŠãŸãŸã¾ã‚Œã‚‹å‰ã«è¡¨ç¤ºã•ã‚Œã‚‹ï¼‰ã§ã‚ã‚‹ã“ã¨ã§ã™ã€‚ãƒ–ãƒ­ã‚°ã¸ã®èª˜å°ãƒªãƒ³ã‚¯ã‚’æ˜ç¢ºã«ç¤ºã—ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¯3ã€œ5å€‹ç¨‹åº¦ï¼ˆå¤šã™ãã‚‹ã¨ã‚¹ãƒ‘ãƒ æ‰±ã„ï¼‰ã«ã—ã¾ã™ã€‚

### æŠ•ç¨¿ã‚¿ã‚¤ãƒŸãƒ³ã‚°

YouTube Shortsã¯19:00ã€œ22:00ã®æŠ•ç¨¿ãŒæœ€ã‚‚è¦–è´ã•ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚äºˆç´„æŠ•ç¨¿æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¾ã—ã‚‡ã†ã€‚

æ›œæ—¥åˆ¥ã®å‚¾å‘ã¯ã€å¹³æ—¥ãŒé€šå‹¤ãƒ»å¸°å®…æ™‚é–“ï¼ˆ7:00ã€œ9:00ã€18:00ã€œ20:00ï¼‰ã€åœŸæ—¥ãŒæ˜¼éãã€œå¤œï¼ˆ13:00ã€œ22:00ï¼‰ã§ã™ã€‚

## é‹ç”¨ã‚³ã‚¹ãƒˆã®å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿

å®Ÿéš›ã«1é€±é–“é‹ç”¨ã—ãŸéš›ã®ã‚³ã‚¹ãƒˆã‚’å…¬é–‹ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ¬æ ¼é‹ç”¨å‰ã«ã‚³ã‚¹ãƒˆã‚’è¦‹ç©ã‚‚ã‚Œã¾ã™ã€‚

1é€±é–“ï¼ˆ7è¨˜äº‹ Ã— 3æœ¬ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ = 21å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼‰ã®é‹ç”¨ã‚³ã‚¹ãƒˆã‚’å®Ÿæ¸¬ã—ã¾ã—ãŸã€‚

Azure GPT-4ã¯è¦ç´„ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«ä½¿ç”¨ã•ã‚Œã€æœˆé–“ã‚³ã‚¹ãƒˆã¯ç´„Â¥800ã§ã™ã€‚Azure FLUXã¯ç”»åƒç”Ÿæˆã«ä½¿ç”¨ã•ã‚Œã€æœˆé–“ã‚³ã‚¹ãƒˆã¯ç´„Â¥1,200ã§ã™ã€‚Azure TTSã¯éŸ³å£°åˆæˆã«ä½¿ç”¨ã•ã‚Œã€æœˆé–“ã‚³ã‚¹ãƒˆã¯ç´„Â¥600ã§ã™ã€‚åˆè¨ˆã§æœˆé–“ç´„Â¥2,600ã¨ãªã‚Šã¾ã™ã€‚

ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãƒã‚¤ãƒ³ãƒˆã¯ã€AIå‹•ç”»ç”Ÿæˆã‚’ä½¿ã‚ãšé™æ­¢ç”» + ãƒ•ãƒªãƒ¼ç´ æã§ä»£æ›¿ã™ã‚‹ã“ã¨ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½ãªç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã€ãƒãƒƒãƒå‡¦ç†ã§APIå‘¼ã³å‡ºã—ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã§ã™ã€‚

æ³¨æ„ç‚¹ã¨ã—ã¦ã€ä¸Šè¨˜ã¯é€šå¸¸åˆ©ç”¨æ™‚ã®ã‚³ã‚¹ãƒˆã§ã™ã€‚å¤§é‡ã®è¨˜äº‹ã‚’ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ã¨ã€ã‚³ã‚¹ãƒˆãŒè·³ã­ä¸ŠãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æœ¬æ ¼é‹ç”¨å‰ã«ã€å¿…ãšå°‘é‡ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã—ã¦ã‚³ã‚¹ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

å®Ÿéš›ã®é‹ç”¨ã§é­é‡ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹å•é¡Œã¨ã€ãã®è§£æ±ºç­–ã‚’ã¾ã¨ã‚ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æƒ…å ±ã¯ã€å®Ÿéš›ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’é‹ç”¨ã™ã‚‹ä¸­ã§å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ã§ã™ã€‚

### Q1: éŸ³å£°ãŒé€”åˆ‡ã‚Œã‚‹ãƒ»ãƒã‚¤ã‚ºãŒå…¥ã‚‹

åŸå› ã¯ã€Azure TTSã®ä¸€æ™‚çš„ãªå•é¡Œã€ã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸å®‰å®šã•ã§ã™ã€‚

è§£æ±ºç­–ã¨ã—ã¦ã€ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¾ã™ã€‚

```python
import time

max_retries = 3
for attempt in range(max_retries):
    try:
        synthesizer.speak_text_async(article['content']).get()
        break
    except Exception as e:
        if attempt == max_retries - 1:
            raise e
        time.sleep(2)
```

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€æœ€å¤§3å›ã¾ã§éŸ³å£°åˆæˆã‚’å†è©¦è¡Œã—ã¾ã™ã€‚å¤±æ•—ã—ãŸå ´åˆã¯2ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã™ã‚‹ã“ã¨ã§ã€ä¸€æ™‚çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã§ãã¾ã™ã€‚

### Q2: MoviePyã§ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹

åŸå› ã¯ã€å¤§é‡ã®å‹•ç”»ã‚¯ãƒªãƒƒãƒ—ã‚’åŒæ™‚ã«ãƒ¡ãƒ¢ãƒªä¸Šã«ä¿æŒã—ã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚

è§£æ±ºç­–ã¯ã€å„è¨˜äº‹ã”ã¨ã«å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã‹ã‚‰ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã€`clip.close()`ã‚’ç¢ºå®Ÿã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã€å¿…è¦ã«å¿œã˜ã¦`gc.collect()`ã§æ˜ç¤ºçš„ã«ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã“ã¨ã§ã™ã€‚

```python
import gc

# å‹•ç”»å‡¦ç†å¾Œ
final_video.close()
gc.collect()
```

MoviePyã¯å¤§é‡ã®ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã™ã‚‹ãŸã‚ã€é©åˆ‡ãªãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ãŒé‡è¦ã§ã™ã€‚ç‰¹ã«é•·æ™‚é–“ã®å‹•ç”»ã‚„å¤§é‡ã®è¨˜äº‹ã‚’å‡¦ç†ã™ã‚‹å ´åˆã¯ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

### Q3: ç”Ÿæˆã•ã‚ŒãŸç”»åƒãŒè¨˜äº‹å†…å®¹ã¨åˆã‚ãªã„

åŸå› ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”ŸæˆãŒæŠ½è±¡çš„ã™ãã‚‹ã€ã¾ãŸã¯å…·ä½“æ€§ã«æ¬ ã‘ã‚‹ã“ã¨ã§ã™ã€‚

è§£æ±ºç­–ã¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚ˆã‚Šå…·ä½“çš„ã«ã—ã¾ã™ã€‚

```python
"content": (
    "ã‚ãªãŸã¯æ˜ ç”»ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚"
    "è¨˜äº‹ã®æ ¸å¿ƒçš„ãªå ´æ‰€ã‚„é›°å›²æ°—ã‚’ã€ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦æå†™ã—ã¦ãã ã•ã„ï¼š"
    "1. å…·ä½“çš„ãªå ´æ‰€ï¼ˆéƒ½å¸‚ã€è‡ªç„¶ã€å»ºç‰©ãªã©ï¼‰"
    "2. æ™‚é–“å¸¯ã‚„å¤©å€™"
    "3. è‰²èª¿ã‚„ãƒ ãƒ¼ãƒ‰"
    "4. è±¡å¾´çš„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"
)
```

GPT-4ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã•ã›ã‚‹éš›ã€ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€è¨˜äº‹å†…å®¹ã«å³ã—ãŸç”»åƒãŒç”Ÿæˆã•ã‚Œã‚„ã™ããªã‚Šã¾ã™ã€‚

### Q4: è¨˜äº‹ãŒèªè­˜ã•ã‚Œãªã„

åŸå› ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«åãŒè¦å‰‡ã«å¾“ã£ã¦ã„ãªã„ã“ã¨ã§ã™ã€‚

è§£æ±ºç­–ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’`YYYYMMDD_ã‚¿ã‚¤ãƒˆãƒ«.md`å½¢å¼ã«å¤‰æ›´ã™ã‚‹ã“ã¨ã€æ—¥ä»˜éƒ¨åˆ†ãŒæ­£ç¢ºãª8æ¡ã®æ•°å­—ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã€ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãŒ`.md`ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã™ã€‚

### Q5: å‹•ç”»ãŒ60ç§’ã‚’è¶…ãˆã¦ã—ã¾ã†

åŸå› ã¯ã€è¨˜äº‹æ•°ãŒå¤šã™ãã‚‹ã€ã¾ãŸã¯å„è¨˜äº‹ã®è¦ç´„ãŒé•·ã™ãã‚‹ã“ã¨ã§ã™ã€‚

è§£æ±ºç­–ã¯ã€è¨˜äº‹æ•°ã‚’3ã€œ5å€‹ã«åˆ¶é™ã™ã‚‹ã“ã¨ã€GPT-4ã¸ã®è¦ç´„æŒ‡ç¤ºã§æ–‡å­—æ•°ã‚’ã•ã‚‰ã«å‰Šæ¸›ï¼ˆ300æ–‡å­—ãªã©ï¼‰ã™ã‚‹ã“ã¨ã€è¤‡æ•°ã®çŸ­ã„å‹•ç”»ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã§ã™ã€‚

### Q6: Canvaã§å­—å¹•è¿½åŠ æ™‚ã«æ—¥æœ¬èªãŒæ–‡å­—åŒ–ã‘ã™ã‚‹

åŸå› ã¯ã€ãƒ•ã‚©ãƒ³ãƒˆãŒæ—¥æœ¬èªã«å¯¾å¿œã—ã¦ã„ãªã„ã“ã¨ã§ã™ã€‚

è§£æ±ºç­–ã¯ã€æ—¥æœ¬èªå¯¾å¿œãƒ•ã‚©ãƒ³ãƒˆã‚’é¸æŠï¼ˆNoto Sans JPã€æºãƒè§’ã‚´ã‚·ãƒƒã‚¯ãªã©ï¼‰ã™ã‚‹ã“ã¨ã€Canvaã®ã€Œè¨€èªè¨­å®šã€ã§æ—¥æœ¬èªã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã™ã€‚

## ä»Šå¾Œã®æ”¹å–„ã‚¢ã‚¤ãƒ‡ã‚¢

ã‚·ã‚¹ãƒ†ãƒ ã®å°†æ¥çš„ãªæ‹¡å¼µå¯èƒ½æ€§ã«ã¤ã„ã¦ã‚‚è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ã•ã‚‰ã«é«˜åº¦ãªæ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

### 1. å®Œå…¨è‡ªå‹•å­—å¹•ç”Ÿæˆ

Whisper APIã‚’ä½¿ã£ã¦éŸ³å£°ã‹ã‚‰è‡ªå‹•ã§å­—å¹•ã‚’ç”Ÿæˆã—ã€`MoviePy`ã®`TextClip`ã§å‹•ç”»ã«ç„¼ãè¾¼ã‚€ä»•çµ„ã¿ã‚’å®Ÿè£…äºˆå®šã§ã™ã€‚

å®Ÿè£…ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ç¤ºã—ã¾ã™ã€‚

```python
import openai

# Whisperã§éŸ³å£°ã‹ã‚‰å­—å¹•ç”Ÿæˆ
with open(audio_path, "rb") as audio_file:
    transcript = openai.Audio.transcribe(
        model="whisper-1",
        file=audio_file,
        response_format="srt"
    )

# SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦TextClipã‚’ç”Ÿæˆ
# MoviePyã§å‹•ç”»ã«ç„¼ãè¾¼ã¿
```

ã“ã®æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã‚Œã°ã€Canvaã§ã®æ‰‹å‹•å­—å¹•è¿½åŠ ãŒä¸è¦ã«ãªã‚Šã€å®Œå…¨è‡ªå‹•åŒ–ã«ä¸€æ­©è¿‘ã¥ãã¾ã™ã€‚

### 2. A/Bãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–

è¤‡æ•°ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚„ã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªå‹•ç”Ÿæˆã—ã€YouTube Analytics APIã¨é€£æºã—ã¦ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®é«˜ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ä»•çµ„ã¿ã‚‚æ¤œè¨ã—ã¦ã„ã¾ã™ã€‚

### 3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‹ãƒ¥ãƒ¼ã‚¹å¯¾å¿œ

RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹APIã¨é€£æºã—ã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è‡ªå‹•ã§è¨˜äº‹åŒ– â†’ å‹•ç”»åŒ–ã™ã‚‹å®Œå…¨è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã‚‚è¦–é‡ã«å…¥ã‚Œã¦ã„ã¾ã™ã€‚

### 4. ãƒãƒ«ãƒè¨€èªå¯¾å¿œ

Azure TTSã¯å¤šè¨€èªå¯¾å¿œã—ã¦ã„ã‚‹ãŸã‚ã€è‹±èªãƒ»ä¸­å›½èªãƒ»éŸ“å›½èªãªã©ã®éŸ³å£°ã‚‚ç”Ÿæˆå¯èƒ½ã§ã™ã€‚ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹ã‚’è¦‹æ®ãˆãŸå¤šè¨€èªå‹•ç”»ç”Ÿæˆã‚‚å®Ÿç¾å¯èƒ½ã§ã™ã€‚

### 5. YouTube APIã«ã‚ˆã‚‹è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

YouTube Data APIã‚’ä½¿ã£ã¦ã€å‹•ç”»ã®è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ã§å®Ÿç¾ã§ãã‚Œã°ã€çœŸã®æ„å‘³ã§ã®å®Œå…¨è‡ªå‹•åŒ–ãŒé”æˆã§ãã¾ã™ã€‚

## ã¾ã¨ã‚

æœ¬è¨˜äº‹ã§ã¯ã€LangGraphã‚’ç”¨ã„ãŸè‡ªå‹•ãƒ‹ãƒ¥ãƒ¼ã‚¹å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å…¨å®¹ã‚’ã€ã‚³ãƒ¼ãƒ‰ã®è©³ç´°ãªè§£èª¬ã¨ã¨ã‚‚ã«ãŠä¼ãˆã—ã¾ã—ãŸã€‚

å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã€LangGraphã«ã‚ˆã‚‹çŠ¶æ…‹ç®¡ç†ã¨å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®æ˜ç¢ºåŒ–ã€Azure AIã‚µãƒ¼ãƒ“ã‚¹ã®åŠ¹æœçš„ãªçµ„ã¿åˆã‚ã›ã€ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®ãŸã‚ã®æŠ€è¡“é¸å®šã€å®Ÿç”¨æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ç´°ã‹ãªå·¥å¤«ãŒã‚ã‚Šã¾ã™ã€‚

é‡è¦ãªç•™æ„ç‚¹ã¨ã—ã¦ã€ç”Ÿæˆã•ã‚Œã‚‹ã®ã¯ã€Œç´ æå‹•ç”»ã€ã§ã‚ã‚Šã€Canvaãªã©ã§ã®ç·¨é›†ãŒå¿…é ˆã§ã‚ã‚‹ã“ã¨ã€BGMã€SEã€å­—å¹•ã€ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãƒ»ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã¯æ‰‹å‹•ã§è¿½åŠ ã™ã‚‹ã“ã¨ã€è‘—ä½œæ¨©ãƒ»è‚–åƒæ¨©ã¸ã®é…æ…®ãŒä¸å¯æ¬ ã§ã‚ã‚‹ã“ã¨ã€Azureæ–™é‡‘ã®å¾“é‡èª²é‡‘ã«æ³¨æ„ã™ã‚‹ã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã¾ã™ã€‚

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’æ›¸ãã ã‘ã§YouTubeã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç´ æã‚‚è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ã¨ã„ã†ã€åŠ¹ç‡çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

å®Œæˆå“ã«ã™ã‚‹ã«ã¯è¿½åŠ ã®ç·¨é›†ä½œæ¥­ãŒå¿…è¦ã§ã™ãŒã€ãã‚Œã§ã‚‚è¨˜äº‹åŸ·ç­†ã«é›†ä¸­ã—ãªãŒã‚‰ã€å‹•ç”»ã¨ã„ã†æ–°ã—ã„ãƒãƒ£ãƒãƒ«ã§è¦–è´è€…ã«ãƒªãƒ¼ãƒã§ãã‚‹å¤§ããªãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚Šã¾ã™ã€‚

è¨˜äº‹åŸ·ç­†ã¨YouTubeé‹å–¶ã®ä¸¡ç«‹ã«æ‚©ã‚“ã§ã„ã‚‹æ–¹ã¯ã€ãœã²ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
