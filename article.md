```bash
uv add azure-cognitiveservices-speech dotenv langchain langgraph openai langchain_openai moviepy typer
```
---
# LangGraphÃ—ç”ŸæˆAIã§è‡ªå‹•ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹

## 1. ã¯ã˜ã‚ã«

### æœ¬è¨˜äº‹ã§å®Ÿç¾ã§ãã‚‹ã“ã¨

ã€Œæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¨˜äº‹ã•ãˆã‚ã‚Œã°ã€è‡ªå‹•ã§è¦ç´„ãƒ»èª­ã¿ä¸Šã’ãƒ»ç”»åƒç”Ÿæˆãƒ»å‹•ç”»ç·¨é›†ã¾ã§å®Œäº†ã™ã‚‹ã€â€•â€•ãã‚“ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿéš›ã«æ§‹ç¯‰ã—ã¾ã—ãŸã€‚

**å®Œæˆã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®æµã‚Œï¼š**
1. Markdownå½¢å¼ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’æŒ‡å®šæœŸé–“ã§è‡ªå‹•æŠ½å‡º
2. GPTã§ã€Œè¦–è´è€…ã‚’æƒ¹ãã¤ã‘ã‚‹ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã€ã«è¦ç´„
3. Azure Speechã§è‡ªç„¶ãªæ—¥æœ¬èªéŸ³å£°ã‚’ç”Ÿæˆ
4. DALL-E 3ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è±¡å¾´ã™ã‚‹ç¸¦é•·ç”»åƒã‚’ç”Ÿæˆ
5. MoviePyã§ç”»åƒãƒ»å‹•ç”»ç´ æã‚’5ç§’å˜ä½ã§å‹•çš„ã«åˆ‡ã‚Šæ›¿ãˆãªãŒã‚‰åˆæˆ
6. æœ€çµ‚çš„ã«YouTube Shorts/TikTokå‘ã‘ã®ç¸¦å‹å‹•ç”»ï¼ˆ9:16ï¼‰ãŒå®Œæˆ

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ãˆã°ã€æ¯æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ç”¨æ„ã™ã‚‹ã ã‘ã§ã€å¾Œã¯ã‚³ãƒãƒ³ãƒ‰ä¸€ç™ºã§å‹•ç”»ç´ æãŒè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã™ã€‚

### ãªãœLangGraphã‚’é¸ã‚“ã ã®ã‹ï¼šLangChainã¨ã®é•ã„

LangChainã§ã‚‚ãƒã‚§ãƒ¼ãƒ³ã‚’ç¹‹ã’ã°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ä½œã‚Œã¾ã™ã€‚ã—ã‹ã—ã€ä»Šå›ã®ã‚ˆã†ãªã€Œè¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµŒã¦æœ€çµ‚æˆæœç‰©ã‚’ä½œã‚‹ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯ã€LangGraphãŒåœ§å€’çš„ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚

**LangGraphã®3ã¤ã®ãƒ¡ãƒªãƒƒãƒˆï¼š**

1. **çŠ¶æ…‹ç®¡ç†ãŒæ˜ç¢º**
   å„ãƒãƒ¼ãƒ‰ãŒå…±é€šã®`State`ã‚’å‚ç…§ãƒ»æ›´æ–°ã™ã‚‹ãŸã‚ã€ã€Œã©ã®ãƒãƒ¼ãƒ‰ãŒã©ã‚“ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãŸã‹ã€ãŒä¸€ç›®ç­ç„¶ã§ã™ã€‚

2. **ãƒ­ã‚°ã¨ãƒ‡ãƒãƒƒã‚°ãŒå®¹æ˜“**
   ãƒãƒ¼ãƒ‰ã”ã¨ã«å‡¦ç†çµæœã‚’JSONLå½¢å¼ã§è¨˜éŒ²ã§ãã‚‹ãŸã‚ã€å¤±æ•—æ™‚ã®åŸå› ç‰¹å®šãŒç°¡å˜ã§ã™ã€‚

3. **æ‹¡å¼µæ€§ãŒé«˜ã„**
   ä¾‹ãˆã°ã€Œç¿»è¨³ãƒãƒ¼ãƒ‰ã€ã‚„ã€ŒSNSè‡ªå‹•æŠ•ç¨¿ãƒãƒ¼ãƒ‰ã€ã‚’å¾Œã‹ã‚‰è¿½åŠ ã—ãŸã„å ´åˆã‚‚ã€ã‚°ãƒ©ãƒ•ã«æ–°ã—ã„ãƒãƒ¼ãƒ‰ã‚’åŠ ãˆã‚‹ã ã‘ã§æ¸ˆã¿ã¾ã™ã€‚

```python
# LangChainã®å ´åˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã ãŒæ‹¡å¼µãŒé›£ã—ã„ï¼‰
chain = prompt | llm | parser

# LangGraphã®å ´åˆï¼ˆçŠ¶æ…‹ç®¡ç†ï¼‹åˆ†å²ãŒå¯èƒ½ï¼‰
graph.add_node("fetch", fetch_node)
graph.add_node("generate", generate_node)
graph.add_node("create_video", video_node)
graph.add_edge("fetch", "generate")
graph.add_edge("generate", "create_video")
```

### æƒ³å®šèª­è€…ã¨å‰æçŸ¥è­˜

**ã“ã®è¨˜äº‹ã¯ã“ã‚“ãªæ–¹ã«ãŠã™ã™ã‚ï¼š**
- LangChainã¯ä½¿ã£ãŸã“ã¨ãŒã‚ã‚‹ãŒã€LangGraphã¯åˆã‚ã¦
- Azure OpenAIã‚„Azure Speechã‚’å®Ÿå‹™ã§æ´»ç”¨ã—ãŸã„
- MoviePyã§ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ã«å‹•ç”»ç·¨é›†ã‚’ã—ã¦ã¿ãŸã„
- AIç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«èˆˆå‘³ãŒã‚ã‚‹

**å‰æçŸ¥è­˜ï¼š**
- Pythonã®åŸºæœ¬æ–‡æ³•ï¼ˆã‚¯ãƒ©ã‚¹ã€éåŒæœŸå‡¦ç†ã¯ä¸è¦ï¼‰
- OpenAI APIã®åŸºæœ¬çš„ãªä½¿ã„æ–¹
- CLIãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡ŒçµŒé¨“

### ã‚·ã‚¹ãƒ†ãƒ ã®å…¨ä½“åƒ

```
[Markdownè¨˜äº‹]
    â†“
[fetch_articles] â† GPTã§è¦ç´„
    â†“
[generate_assets] â† Azure Speech + DALL-E 3
    â†“
[create_video] â† MoviePyã§åˆæˆ
    â†“
[YouTube Shortsç”¨å‹•ç”».mp4]
```

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼š**
- **LangGraph:** ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹ç®¡ç†
- **Azure OpenAI:** è¦ç´„ç”Ÿæˆãƒ»ç”»åƒç”Ÿæˆ
- **Azure Speech:** æ—¥æœ¬èªãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
- **MoviePy:** å‹•ç”»åˆæˆãƒ»ç·¨é›†
- **Typer:** CLIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

---

## 2. æŠ€è¡“é¸å®šã®ç†ç”±ã¨ä»£æ›¿æ¡ˆã¨ã®æ¯”è¼ƒ

### LangGraph vs å˜ç´”ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼šçŠ¶æ…‹ç®¡ç†ãƒ»ãƒ­ã‚°ãƒ»æ‹¡å¼µæ€§

æœ€åˆã¯ã€ŒPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã§é †ç•ªã«å‡¦ç†ã‚’æ›¸ã‘ã°ã„ã„ã®ã§ã¯ï¼Ÿã€ã¨è€ƒãˆã¦ã„ã¾ã—ãŸã€‚å®Ÿéš›ã€å°è¦æ¨¡ãªã‚‰å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚

ã—ã‹ã—ã€ä»¥ä¸‹ã®ã‚ˆã†ãªè¦ä»¶ãŒå‡ºã¦ãã‚‹ã¨ã€ã™ãã«ç ´ç¶»ã—ã¾ã™ï¼š

**è¤‡é›‘åŒ–ã™ã‚‹è¦ä»¶ã®ä¾‹ï¼š**
- ã€Œè¨˜äº‹ãŒ0ä»¶ã ã£ãŸå ´åˆã¯å‹•ç”»ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸã„ã€
- ã€Œç”»åƒç”Ÿæˆã«å¤±æ•—ã—ãŸã‚‰ãƒªãƒˆãƒ©ã‚¤ã—ãŸã„ã€
- ã€Œå„ã‚¹ãƒ†ãƒƒãƒ—ã®å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆã‚’ãƒ­ã‚°ã«æ®‹ã—ãŸã„ã€

ã“ã†ã—ãŸ**æ¡ä»¶åˆ†å²ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒ­ã‚°ç®¡ç†**ã‚’ç´ ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å®Ÿè£…ã™ã‚‹ã¨ã€ifæ–‡ã¨try-exceptãŒå…¥ã‚Šä¹±ã‚ŒãŸèª­ã¿ã«ãã„ã‚³ãƒ¼ãƒ‰ã«ãªã‚Šã¾ã™ã€‚

**LangGraphã‚’ä½¿ã†ã¨ï¼š**
```python
# çŠ¶æ…‹ã¯ã™ã¹ã¦Stateã«é›†ç´„
class AgentState(TypedDict):
    articles: list[ArticleData]
    audio_files: list[str]
    image_files: list[str]
    start_date: str
    end_date: str
    output_dir: str

# å„ãƒãƒ¼ãƒ‰ã¯å¿…è¦ãªå‡¦ç†ã ã‘ã«é›†ä¸­
def fetch_articles_node(state: AgentState) -> dict:
    # è¨˜äº‹å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
    return {"articles": articles}
```

ã“ã‚Œã«ã‚ˆã‚Šã€**å„ãƒãƒ¼ãƒ‰ãŒç‹¬ç«‹ã—ãŸãƒ†ã‚¹ãƒˆå¯èƒ½ãªé–¢æ•°**ã¨ã—ã¦æ©Ÿèƒ½ã—ã€ä¿å®ˆæ€§ãŒæ ¼æ®µã«å‘ä¸Šã—ã¾ã™ã€‚

### Azure OpenAI/Speech vs ä»–ã‚µãƒ¼ãƒ“ã‚¹ï¼šå“è³ªãƒ»ã‚³ã‚¹ãƒˆãƒ»æ—¥æœ¬èªå¯¾å¿œ

**ãªãœAzure OpenAIãªã®ã‹ï¼Ÿ**

OpenAI APIã®ç›´æ¥åˆ©ç”¨ã¨æ¯”è¼ƒã—ãŸå ´åˆã®ãƒ¡ãƒªãƒƒãƒˆï¼š
- ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘ã®SLAä¿è¨¼
- æ—¥æœ¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
- Azure Creditæ´»ç”¨ã§ã‚³ã‚¹ãƒˆæœ€é©åŒ–

**ãªãœAzure Speechãªã®ã‹ï¼Ÿ**

å¸‚è²©ã®TTSãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨æ¯”è¼ƒï¼š

| ã‚µãƒ¼ãƒ“ã‚¹ | æ—¥æœ¬èªå“è³ª | æ„Ÿæƒ…è¡¨ç¾ | ã‚³ã‚¹ãƒˆ |
|---------|-----------|---------|--------|
| Google TTS | â—‹ | â–³ | å®‰ã„ |
| Amazon Polly | â—‹ | â–³ | å®‰ã„ |
| **Azure Speech** | â— | â— | ã‚„ã‚„é«˜ã„ |
| ElevenLabs | â— | â— | é«˜ã„ |

Azure Speechã®`ja-JP-NanamiNeural`ã¯ã€**ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ã®ã‚ˆã†ãªè‡ªç„¶ãªã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³**ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚ç‰¹ã«ã€Œå¥èª­ç‚¹ã§ã®é–“ã®å–ã‚Šæ–¹ã€ãŒå„ªç§€ã§ã€æ©Ÿæ¢°éŸ³å£°ã£ã½ã•ãŒå¤§å¹…ã«è»½æ¸›ã•ã‚Œã¾ã™ã€‚

### MoviePy vs å‹•ç”»ç”ŸæˆAIï¼ˆSoraç­‰ï¼‰ï¼šã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®æˆ¦ç•¥

å½“åˆã¯ã€ŒOpenAI Soraã§å…¨éƒ¨ç”Ÿæˆã™ã‚Œã°ã„ã„ã®ã§ã¯ï¼Ÿã€ã¨è€ƒãˆã¦ã„ã¾ã—ãŸã€‚

**ã—ã‹ã—ç¾å®Ÿã¯ï¼š**
- Soraã®æ–™é‡‘ï¼š1åˆ†å‹•ç”»ã§ç´„$10ã€œ20ï¼ˆæ¨å®šï¼‰
- æ¯æ—¥æŠ•ç¨¿ã™ã‚‹ã¨æœˆ$300ã€œ600ã®ã‚³ã‚¹ãƒˆ
- å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ç¶™ç¶šå›°é›£

**ãã“ã§æ¡ç”¨ã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æˆ¦ç•¥ï¼š**

1. **å†’é ­5ç§’ï¼š** DALL-E 3ã§ç”Ÿæˆã—ãŸè±¡å¾´çš„ãªç”»åƒï¼ˆ$0.04/æšï¼‰
2. **ä»¥é™ï¼š** ãƒ•ãƒªãƒ¼ç´ æå‹•ç”»ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ‡ã‚Šå‡ºã—ã¦æŒ¿å…¥ï¼ˆç„¡æ–™ï¼‰

ã“ã®æ§‹æˆã«ã‚ˆã‚Šã€**1æœ¬ã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆã‚’$0.10ä»¥ä¸‹**ã«æŠ‘ãˆã¤ã¤ã€è¦–è´è€…ã‚’é£½ãã•ã›ãªã„å‹•ç”»ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚

**ãªãœå®Œå…¨é™æ­¢ç”»ã§ã¯ãƒ€ãƒ¡ãªã®ã‹ï¼Ÿ**

åˆæœŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€Œç”Ÿæˆç”»åƒ1æšã‚’1åˆ†é–“è¡¨ç¤ºã€ã—ã¦ã„ã¾ã—ãŸãŒã€YouTube Analyticsã§**è¦–è´ç¶­æŒç‡ãŒ20ç§’ã§50%ä»¥ä¸‹**ã«è½ã¡ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚

**5ç§’å˜ä½ã§ç”»é¢ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹**ã“ã¨ã§ã€è¦–è´ç¶­æŒç‡ãŒ**å¹³å‡65%**ã¾ã§æ”¹å–„ã—ã¾ã—ãŸã€‚

---

ã“ã“ã¾ã§ãŒ**ç„¡æ–™ãƒ‘ãƒ¼ãƒˆ**ã§ã™ã€‚èª­è€…ã«ã€Œã“ã®æŠ€è¡“é¸å®šã«ã¯æ˜ç¢ºãªç†ç”±ãŒã‚ã‚‹ã€ã¨ç´å¾—ã—ã¦ã‚‚ã‚‰ã„ã€æœ‰æ–™éƒ¨åˆ†ã¸ã®æœŸå¾…ã‚’é«˜ã‚ã¾ã™ã€‚

---

## 3. é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã“ã“ã‹ã‚‰æœ‰æ–™ãƒ‘ãƒ¼ãƒˆã«å…¥ã‚Šã¾ã™ã€‚å®Ÿéš›ã«æ‰‹ã‚’å‹•ã‹ã—ã¦å®Ÿè£…ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã¾ã§è©³ç´°ã«è§£èª¬ã—ã¾ã™ã€‚

### uv/poetryã«ã‚ˆã‚‹ç’°å¢ƒæ§‹ç¯‰

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯**uv**ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚pipã‚„poetryã¨æ¯”è¼ƒã—ã¦ã€ä¾å­˜é–¢ä¿‚ã®è§£æ±ºãŒé«˜é€Ÿã§ã™ã€‚

```bash
# uvã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆã¾ã ã®å ´åˆï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir news-video-pipeline
cd news-video-pipeline

# Python 3.11ç’°å¢ƒã®ä½œæˆ
uv venv --python 3.11
source .venv/bin/activate  # Windowsã®å ´åˆ: .venv\Scripts\activate

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install langgraph langchain-openai azure-cognitiveservices-speech \
    moviepy pillow typer python-dotenv
```

**ä¾å­˜é–¢ä¿‚ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šï¼ˆæ¨å¥¨ï¼‰ï¼š**
```bash
# requirements.txtã«æ›¸ãå‡ºã—
uv pip freeze > requirements.txt
```

### Azure ãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆæ‰‹é †

#### 1. Azure OpenAIãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆ

**Azure Portalã§ã®æ‰‹é †ï¼š**
1. ã€Œãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆã€â†’ã€ŒAzure OpenAIã€ã‚’æ¤œç´¢
2. ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¯`Japan East`ã‚’é¸æŠï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å‰Šæ¸›ï¼‰
3. ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã¯`Standard S0`
4. ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†å¾Œã€ã€Œã‚­ãƒ¼ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€ã‚’ãƒ¡ãƒ¢

**ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ï¼š**
- GPT-4o: `gpt-4o`ï¼ˆè¦ç´„ç”¨ï¼‰
- DALL-E 3: `dall-e-3`ï¼ˆç”»åƒç”Ÿæˆç”¨ï¼‰

#### 2. Azure Speech Serviceã®ä½œæˆ

1. ã€Œãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆã€â†’ã€ŒSpeechã€ã‚’æ¤œç´¢
2. ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¯`Japan East`
3. ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã¯`Free F0`ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰ã¾ãŸã¯`Standard S0`
4. ã€Œã‚­ãƒ¼ã¨ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã€ã‚’ãƒ¡ãƒ¢

**é‡è¦ï¼š** Speech Serviceã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¨OpenAIã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¯**ä¸€è‡´ã•ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“**ãŒã€åŒã˜ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã«ã™ã‚‹ã“ã¨ã§ãƒ­ã‚°ç®¡ç†ãŒæ¥½ã«ãªã‚Šã¾ã™ã€‚

### ImageMagick/FFmpegã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨æ³¨æ„ç‚¹

MoviePyã¯å†…éƒ¨ã§ImageMagickã¨FFmpegã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

**macOS:**
```bash
brew install imagemagick ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install imagemagick ffmpeg
```

**Windows:**
1. [ImageMagickå…¬å¼](https://imagemagick.org/script/download.php)ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
2. [FFmpegå…¬å¼](https://ffmpeg.org/download.html)ã‹ã‚‰ãƒã‚¤ãƒŠãƒªã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€PATHã«è¿½åŠ 

**MoviePyã§ImageMagickã®ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼š**
```python
# Windowsã®å ´åˆã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§æ˜ç¤ºçš„ã«æŒ‡å®šãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹
from moviepy.config import change_settings
change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.0-Q16\magick.exe"})
```

### .envè¨­å®šã¨Configã‚¯ãƒ©ã‚¹ã®å®Ÿè£…

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```bash
# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o
AZURE_OPENAI_IMAGE_DEPLOYMENT=dall-e-3

# Azure Speech
AZURE_SPEECH_KEY=your-speech-key
AZURE_SPEECH_REGION=japaneast

# ãã®ä»–
ARTICLE_DIR=./article
OUTPUT_DIR=./output
MOVIE_DIR=./movie
```

**Configã‚¯ãƒ©ã‚¹ã®å®Ÿè£…ï¼š**

```python
from dataclasses import dataclass
from dotenv import load_dotenv
import os

load_dotenv()

@dataclass
class Config:
    # Azure OpenAI
    azure_openai_endpoint: str = os.getenv("AZURE_OPENAI_ENDPOINT", "")
    azure_openai_api_key: str = os.getenv("AZURE_OPENAI_API_KEY", "")
    azure_openai_api_version: str = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
    azure_openai_chat_deployment: str = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT", "gpt-4o")
    azure_openai_image_deployment: str = os.getenv("AZURE_OPENAI_IMAGE_DEPLOYMENT", "dall-e-3")

    # Azure Speech
    azure_speech_key: str = os.getenv("AZURE_SPEECH_KEY", "")
    azure_speech_region: str = os.getenv("AZURE_SPEECH_REGION", "japaneast")

    # Directories
    article_dir: str = os.getenv("ARTICLE_DIR", "./article")
    output_dir: str = os.getenv("OUTPUT_DIR", "./output")
    movie_dir: str = os.getenv("MOVIE_DIR", "./movie")

config = Config()
```

**ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ ï¼ˆæ¨å¥¨ï¼‰ï¼š**
```python
def validate_config():
    required = [
        ("AZURE_OPENAI_ENDPOINT", config.azure_openai_endpoint),
        ("AZURE_OPENAI_API_KEY", config.azure_openai_api_key),
        ("AZURE_SPEECH_KEY", config.azure_speech_key),
    ]
    for name, value in required:
        if not value:
            raise ValueError(f"{name} is not set in .env file")

validate_config()
```

---

## 4. LangGraphã«ã‚ˆã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­è¨ˆ

### StateGraphã®åŸºæœ¬æ§‹é€ 

LangGraphã§ã¯ã€ã™ã¹ã¦ã®ãƒãƒ¼ãƒ‰ãŒå…±é€šã®**State**ã‚’å‚ç…§ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Œèª°ãŒã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã£ãŸã‹ã€ãŒæ˜ç¢ºã«ãªã‚Šã¾ã™ã€‚

**AgentStateã®è¨­è¨ˆï¼š**

```python
from typing import TypedDict, List
from dataclasses import dataclass

@dataclass
class ArticleData:
    """1è¨˜äº‹åˆ†ã®ãƒ‡ãƒ¼ã‚¿"""
    filepath: str          # å…ƒè¨˜äº‹ã®ãƒ‘ã‚¹
    title: str             # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
    display_title: str     # è¡¨ç¤ºç”¨ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè¦‹å‡ºã—ã‹ã‚‰æŠ½å‡ºï¼‰
    content: str           # è¨˜äº‹æœ¬æ–‡
    summary: str           # GPTã«ã‚ˆã‚‹è¦ç´„ï¼ˆåˆæœŸã¯ç©ºï¼‰

class AgentState(TypedDict):
    """ã‚°ãƒ©ãƒ•å…¨ä½“ã§å…±æœ‰ã™ã‚‹çŠ¶æ…‹"""
    # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    start_date: str
    end_date: str
    output_dir: str

    # å„ãƒãƒ¼ãƒ‰ãŒç”Ÿæˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿
    articles: List[ArticleData]      # fetch_articles ãŒç”Ÿæˆ
    audio_files: List[str]            # generate_assets ãŒç”Ÿæˆ
    image_files: List[str]            # generate_assets ãŒç”Ÿæˆ
    final_video_path: str             # create_video ãŒç”Ÿæˆ
```

**TypedDictã‚’ä½¿ã†ç†ç”±ï¼š**
- å‹ãƒ’ãƒ³ãƒˆã«ã‚ˆã‚ŠIDEã®è£œå®ŒãŒåŠ¹ã
- å„ãƒãƒ¼ãƒ‰ãŒã€Œã©ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’èª­ã¿æ›¸ãã™ã‚‹ã‹ã€ãŒæ˜ç¢º
- ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã§ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚å¯èƒ½

### ãƒãƒ¼ãƒ‰é–“ã®çŠ¶æ…‹å—ã‘æ¸¡ã—ã®ä»•çµ„ã¿

LangGraphã®ãƒãƒ¼ãƒ‰ã¯ã€**å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ã‘ã‚’è¿”ã™**è¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚

```python
def fetch_articles_node(state: AgentState) -> dict:
    """è¨˜äº‹ã‚’å–å¾—ã—ã€articlesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°"""
    articles = load_articles(state["start_date"], state["end_date"])

    # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ã‘ã‚’è¿”ã™
    return {"articles": articles}

def generate_assets_node(state: AgentState) -> dict:
    """articlesã‚’èª­ã¿å–ã‚Šã€audio/imageãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    audio_files = []
    image_files = []

    for article in state["articles"]:
        audio = generate_speech(article.summary)
        image = generate_image(article.summary)
        audio_files.append(audio)
        image_files.append(image)

    # 2ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’åŒæ™‚ã«æ›´æ–°
    return {
        "audio_files": audio_files,
        "image_files": image_files
    }
```

**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼š**
- ãƒãƒ¼ãƒ‰ã¯`state`å…¨ä½“ã‚’èª­ã‚ã‚‹ãŒã€**è¿”ã™ã®ã¯å¤‰æ›´åˆ†ã ã‘**
- ã“ã‚Œã«ã‚ˆã‚Šã€ä»–ã®ãƒãƒ¼ãƒ‰ãŒè¨­å®šã—ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’èª¤ã£ã¦ä¸Šæ›¸ãã™ã‚‹ã“ã¨ã‚’é˜²ã’ã‚‹

### ã‚°ãƒ©ãƒ•å®šç¾©ã®ã‚³ãƒ¼ãƒ‰è§£èª¬

```python
from langgraph.graph import StateGraph, END

# ã‚°ãƒ©ãƒ•ã®åˆæœŸåŒ–
workflow = StateGraph(AgentState)

# ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
workflow.add_node("fetch_articles", fetch_articles_node)
workflow.add_node("generate_assets", generate_assets_node)
workflow.add_node("create_video", create_short_video_node)

# ã‚¨ãƒƒã‚¸ï¼ˆãƒãƒ¼ãƒ‰é–“ã®æ¥ç¶šï¼‰ã®å®šç¾©
workflow.set_entry_point("fetch_articles")  # æœ€åˆã®ãƒãƒ¼ãƒ‰
workflow.add_edge("fetch_articles", "generate_assets")
workflow.add_edge("generate_assets", "create_video")
workflow.add_edge("create_video", END)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
app = workflow.compile()
```

**æ¡ä»¶åˆ†å²ã‚’è¿½åŠ ã™ã‚‹å ´åˆï¼š**

```python
def should_continue(state: AgentState) -> str:
    """è¨˜äº‹ãŒ0ä»¶ãªã‚‰å‡¦ç†ã‚’ä¸­æ–­"""
    if len(state["articles"]) == 0:
        return "end"
    return "continue"

workflow.add_conditional_edges(
    "fetch_articles",
    should_continue,
    {
        "continue": "generate_assets",
        "end": END
    }
)
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œã¨ãƒ­ã‚°å‡ºåŠ›

LangGraphã®`.stream()`ã‚’ä½¿ã†ã¨ã€å„ãƒãƒ¼ãƒ‰ã®å®Ÿè¡Œã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–ã§ãã¾ã™ã€‚

```python
def run_pipeline(start_date: str, end_date: str):
    output_dir = f"./output/{start_date}_{end_date}"
    os.makedirs(output_dir, exist_ok=True)

    initial_state = {
        "start_date": start_date,
        "end_date": end_date,
        "output_dir": output_dir,
        "articles": [],
        "audio_files": [],
        "image_files": [],
        "final_video_path": ""
    }

    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
    for event in app.stream(initial_state):
        for node_name, node_output in event.items():
            print(f"âœ“ Node [{node_name}] completed")
            print(f"  Output: {list(node_output.keys())}")

    print(f"\nğŸ¬ Final video: {initial_state['final_video_path']}")
```

**å®Ÿè¡Œä¾‹ï¼š**
```
âœ“ Node [fetch_articles] completed
  Output: ['articles']
âœ“ Node [generate_assets] completed
  Output: ['audio_files', 'image_files']
âœ“ Node [create_video] completed
  Output: ['final_video_path']

ğŸ¬ Final video: ./output/20260201_20260207/final_youtube_short.mp4
```

---

## 5. ã€Node 1ã€‘è¨˜äº‹å–å¾—ã¨è¦ç´„ç”Ÿæˆ

### æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®å®Ÿè£…

è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯`article/20260209_title.md`ã®ã‚ˆã†ãªå‘½åè¦å‰‡ã‚’å‰æã¨ã—ã¾ã™ã€‚

```python
import os
import re
from datetime import datetime
from pathlib import Path

def load_articles_by_date(
    article_dir: str,
    start_date: str,  # "20260201"
    end_date: str     # "20260207"
) -> List[ArticleData]:
    """æŒ‡å®šæœŸé–“ã®è¨˜äº‹ã‚’èª­ã¿è¾¼ã¿"""
    articles = []

    # article/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®mdãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    article_path = Path(article_dir)
    for filepath in article_path.glob("*.md"):
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºï¼ˆä¾‹: 20260209_title.mdï¼‰
        match = re.match(r"(\d{8})_.*\.md", filepath.name)
        if not match:
            continue

        file_date = match.group(1)

        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
        if start_date <= file_date <= end_date:
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()

            # æœ€åˆã®è¦‹å‡ºã—è¡Œã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦æŠ½å‡º
            title_match = re.search(r"^#\s+(.+)$", content, re.MULTILINE)
            display_title = title_match.group(1) if title_match else filepath.stem

            articles.append(ArticleData(
                filepath=str(filepath),
                title=filepath.stem,
                display_title=display_title,
                content=content,
                summary=""  # ã“ã®æ®µéšã§ã¯æœªç”Ÿæˆ
            ))

    return articles
```

**Tipsï¼š** `glob`ã‚’ä½¿ã†ã“ã¨ã§ã€ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¾ã§å†å¸°çš„ã«æ¤œç´¢ã—ãŸã„å ´åˆã¯`rglob`ã«å¤‰æ›´ã§ãã¾ã™ã€‚

### GPTãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

#### URLã‚„ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®é™¤å»æ–¹æ³•

è¨˜äº‹æœ¬æ–‡ã«URLã‚„ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨ã€éŸ³å£°èª­ã¿ä¸Šã’æ™‚ã«ã€Œhttps colon slash slash...ã€ã®ã‚ˆã†ã«èª­ã¾ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚

**å‰å‡¦ç†ã§é™¤å»ã™ã‚‹æ–¹æ³•ï¼š**

```python
import re

def clean_text_for_speech(text: str) -> str:
    """éŸ³å£°èª­ã¿ä¸Šã’ç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    # URLã‚’é™¤å»
    text = re.sub(r'https?://[^\s]+', '', text)

    # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’é™¤å»
    text = re.sub(r'#\w+', '', text)

    # Markdownã®è¦‹å‡ºã—è¨˜å·ã‚’é™¤å»
    text = re.sub(r'^#+\s', '', text, flags=re.MULTILINE)

    # è¤‡æ•°ã®æ”¹è¡Œã‚’1ã¤ã«
    text = re.sub(r'\n{2,}', '\n', text)

    return text.strip()
```

#### ã€Œã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼è¦ç´„ã€ã‚’å®Ÿç¾ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡å…¬é–‹

ãŸã è¦ç´„ã™ã‚‹ã ã‘ã§ãªãã€**è¦–è´è€…ã‚’æƒ¹ãã¤ã‘ã‚‹å†’é ­**ã‚’æ„è­˜ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé‡è¦ã§ã™ã€‚

```python
from langchain_openai import AzureChatOpenAI

def summarize_article(article: ArticleData, config: Config) -> str:
    """GPTã§è¨˜äº‹ã‚’è¦ç´„"""

    llm = AzureChatOpenAI(
        azure_endpoint=config.azure_openai_endpoint,
        api_key=config.azure_openai_api_key,
        api_version=config.azure_openai_api_version,
        deployment_name=config.azure_openai_chat_deployment,
        temperature=0.7
    )

    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
    cleaned_content = clean_text_for_speech(article.content)

    prompt = f"""ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ã€YouTubeã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚

## è¦ä»¶
- 500æ–‡å­—ä»¥å†…ï¼ˆå³å®ˆï¼‰
- å†’é ­ã®1æ–‡ã§è¦–è´è€…ã®èˆˆå‘³ã‚’å¼•ããƒ•ãƒƒã‚¯ï¼ˆã€Œé©šãã¹ãã“ã¨ã«ã€ã€Œã¤ã„ã«ã€ã€Œå®Ÿã¯ã€ãªã©ï¼‰ã‚’å…¥ã‚Œã‚‹
- ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã®è©±ã—è¨€è‘‰
- URLã‚„è¨˜å·ã¯å«ã‚ãªã„
- å°‚é–€ç”¨èªã«ã¯ç°¡å˜ãªèª¬æ˜ã‚’ä»˜ã‘ã‚‹
- çµè«–ã‚’æ˜ç¢ºã«ã™ã‚‹

## å…ƒè¨˜äº‹
{cleaned_content}

## ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿:
"""

    response = llm.invoke(prompt)
    summary = response.content.strip()

    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆè¶…ãˆã¦ã„ã‚‹å ´åˆã¯è­¦å‘Šï¼‰
    if len(summary) > 500:
        print(f"âš ï¸  Warning: Summary too long ({len(summary)} chars)")

    return summary
```

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã®ãƒã‚¤ãƒ³ãƒˆï¼š**

1. **å†’é ­ãƒ•ãƒƒã‚¯ï¼š** YouTube Shortsã¯æœ€åˆ3ç§’ãŒå‹è² ã€‚ã€Œé©šãã¹ãç™ºè¦‹ãŒã€ã€Œã¤ã„ã«å®Ÿç¾ã€ã®ã‚ˆã†ãªè¨€è‘‰ã§æ³¨æ„ã‚’å¼•ã
2. **è©±ã—è¨€è‘‰ï¼š** ã€Œã§ã‚ã‚‹èª¿ã€ã§ã¯ãªãã€Œã§ã™ãƒ»ã¾ã™èª¿ã€
3. **æ–‡å­—æ•°åˆ¶é™ï¼š** éŸ³å£°èª­ã¿ä¸Šã’æ™‚é–“ã‚’60ç§’ä»¥å†…ã«åã‚ã‚‹ãŸã‚ã€500æ–‡å­—ã‚’ä¸Šé™ã¨ã™ã‚‹

#### 500æ–‡å­—åˆ¶é™ã®ç†ç”±ã¨èª¿æ•´æ–¹æ³•

**ãªãœ500æ–‡å­—ãªã®ã‹ï¼Ÿ**

- æ—¥æœ¬èªã®å¹³å‡èª­ã¿ä¸Šã’é€Ÿåº¦ï¼šç´„300æ–‡å­—/åˆ†
- 500æ–‡å­— = ç´„100ç§’ = YouTube Shortsã®ä¸Šé™ï¼ˆ60ç§’ï¼‰ã«ã‚„ã‚„ä½™è£•ã‚’æŒãŸã›ãŸè¨­å®š

**èª¿æ•´ãŒå¿…è¦ãªå ´åˆï¼š**

```python
# ã‚‚ã£ã¨çŸ­ãã—ãŸã„å ´åˆ
# "300æ–‡å­—ä»¥å†…" ã«å¤‰æ›´ â†’ ç´„60ç§’

# é•·ã‚ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã—ãŸã„å ´åˆ
# "700æ–‡å­—ä»¥å†…" ã«å¤‰æ›´ â†’ ç´„140ç§’ï¼ˆTikTokã®3åˆ†å‹•ç”»å‘ã‘ï¼‰
```

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼šMarkdownè§£æã®ç½ 

**ãƒãƒã£ãŸãƒã‚¤ãƒ³ãƒˆ1ï¼šè¦‹å‡ºã—éšå±¤ã®æ‰±ã„**

```markdown
# ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
## ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«
### å°è¦‹å‡ºã—
```

æœ€åˆã®`#`ã ã‘ã‚’æŠ½å‡ºã—ãŸã¤ã‚‚ã‚ŠãŒã€`##`ã‚„`###`ã‚‚æ‹¾ã£ã¦ã—ã¾ã†å ´åˆï¼š

```python
# âŒ é–“é•ã„
title_match = re.search(r"#\s+(.+)$", content, re.MULTILINE)

# âœ… æ­£ã—ã„ï¼ˆè¡Œé ­ã®#1ã¤ã ã‘ã«ãƒãƒƒãƒï¼‰
title_match = re.search(r"^#\s+(.+)$", content, re.MULTILINE)
```

**ãƒãƒã£ãŸãƒã‚¤ãƒ³ãƒˆ2ï¼šã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ãƒ†ã‚­ã‚¹ãƒˆ**

è¨˜äº‹å†…ã«```ã§å›²ã¾ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹ã¨ã€URLã‚„ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®é™¤å»ã§èª¤çˆ†ã—ã¾ã™ã€‚

**å¯¾ç­–ï¼š**
```python
def remove_code_blocks(text: str) -> str:
    """ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»"""
    return re.sub(r'```.*?```', '', text, flags=re.DOTALL)

cleaned = remove_code_blocks(article.content)
cleaned = clean_text_for_speech(cleaned)
```

---

## 6. ã€Node 2ã€‘ã‚¢ã‚»ãƒƒãƒˆç”Ÿæˆã®è‡ªå‹•åŒ–

### Azure Speechå®Ÿè£…ã®è©³ç´°

#### ja-JP-NanamiNeuralã®è¨­å®š

Azure Speechã«ã¯è¤‡æ•°ã®æ—¥æœ¬èªéŸ³å£°ãŒã‚ã‚Šã¾ã™ãŒã€**ãƒ‹ãƒ¥ãƒ¼ã‚¹èª­ã¿ä¸Šã’ã«æœ€é©ãªã®ã¯NanamiNeural**ã§ã™ã€‚

```python
import azure.cognitiveservices.speech as speechsdk
from pathlib import Path

def generate_speech(
    text: str,
    output_path: str,
    config: Config
) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""

    # Speech SDKã®è¨­å®š
    speech_config = speechsdk.SpeechConfig(
        subscription=config.azure_speech_key,
        region=config.azure_speech_region
    )

    # éŸ³å£°è¨­å®šï¼ˆé‡è¦ï¼‰
    speech_config.speech_synthesis_voice_name = "ja-JP-NanamiNeural"

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    audio_config = speechsdk.audio.AudioOutputConfig(
        filename=output_path
    )

    # åˆæˆå®Ÿè¡Œ
    synthesizer = speechsdk.SpeechSynthesizer(
        speech_config=speech_config,
        audio_config=audio_config
    )

    result = synthesizer.speak_text_async(text).get()

    # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        print(f"âœ“ Audio generated: {output_path}")
        return output_path
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation = result.cancellation_details
        raise Exception(f"Speech synthesis canceled: {cancellation.reason}")

    return output_path
```

**éŸ³å£°å“è³ªã®èª¿æ•´ï¼š**

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯16kHz/16bitã§ã™ãŒã€ã‚ˆã‚Šé«˜å“è³ªã«ã—ãŸã„å ´åˆï¼š

```python
# 24kHz/16bitï¼ˆé«˜å“è³ªï¼‰
speech_config.set_speech_synthesis_output_format(
    speechsdk.SpeechSynthesisOutputFormat.Audio24Khz16BitMonoPcm
)
```

#### SSMLæ´»ç”¨ã«ã‚ˆã‚‹èª­ã¿ä¸Šã’èª¿æ•´

SSMLï¼ˆSpeech Synthesis Markup Languageï¼‰ã‚’ä½¿ã†ã¨ã€èª­ã¿ä¸Šã’ã®ç´°ã‹ã„èª¿æ•´ãŒã§ãã¾ã™ã€‚

**åŸºæœ¬çš„ãªSSMLï¼š**

```python
def generate_speech_with_ssml(text: str, output_path: str, config: Config) -> str:
    """SSMLã‚’ä½¿ã£ãŸé«˜åº¦ãªéŸ³å£°ç”Ÿæˆ"""

    # SSMLã§ãƒ©ãƒƒãƒ—
    ssml = f"""
    <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ja-JP">
        <voice name="ja-JP-NanamiNeural">
            <prosody rate="0%">
                {text}
            </prosody>
        </voice>
    </speak>
    """

    speech_config = speechsdk.SpeechConfig(
        subscription=config.azure_speech_key,
        region=config.azure_speech_region
    )

    audio_config = speechsdk.audio.AudioOutputConfig(filename=output_path)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config, audio_config)

    # speak_ssml_asyncã‚’ä½¿ç”¨
    result = synthesizer.speak_ssml_async(ssml).get()

    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return output_path
    else:
        raise Exception(f"SSML synthesis failed: {result.reason}")
```

**SSMLã§ã§ãã‚‹ã“ã¨ï¼š**

| ã‚¿ã‚° | ç”¨é€” | ä¾‹ |
|------|------|-----|
| `<prosody rate="20%">` | èª­ã¿ä¸Šã’é€Ÿåº¦ | 20%é€Ÿã |
| `<prosody pitch="+5%">` | å£°ã®é«˜ã• | ã‚„ã‚„é«˜ã |
| `<break time="500ms"/>` | ä¸€æ™‚åœæ­¢ | 0.5ç§’ã®é–“ |
| `<emphasis level="strong">` | å¼·èª¿ | é‡è¦ãªå˜èª |

**å®Ÿç”¨ä¾‹ï¼šé‡è¦ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å¼·èª¿**

```python
ssml = f"""
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ja-JP">
    <voice name="ja-JP-NanamiNeural">
        é©šãã¹ãã“ã¨ã«ã€<emphasis level="strong">AIãŒè‡ªå‹•ã§å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹</emphasis>æ™‚ä»£ãŒæ¥ã¾ã—ãŸã€‚
        <break time="300ms"/>
        ã“ã‚Œã«ã‚ˆã‚Šã€å‹•ç”»åˆ¶ä½œã®æ™‚é–“ãŒ10åˆ†ã®1ã«çŸ­ç¸®ã•ã‚Œã¾ã™ã€‚
    </voice>
</speak>
```

#### éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªè¨­å®š

**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼š**

| ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | ã‚µã‚¤ã‚ºï¼ˆ60ç§’ï¼‰ | ç”¨é€” |
|------------|--------------|------|
| 8kHz/8bit | 480KB | é›»è©±éŸ³å£°ãƒ¬ãƒ™ãƒ« |
| 16kHz/16bit | 1.9MB | **æ¨å¥¨ï¼ˆæ¨™æº–å“è³ªï¼‰** |
| 24kHz/16bit | 2.8MB | é«˜å“è³ªï¼ˆSNSæŠ•ç¨¿å‘ã‘ï¼‰ |
| 48kHz/16bit | 5.6MB | ãƒ—ãƒ­å“è³ªï¼ˆéå‰°ï¼‰ |

ä»Šå›ã®YouTube Shortsç”¨é€”ã§ã¯**16kHz/16bit**ã§ååˆ†ã§ã™ã€‚

### DALL-E 3ã«ã‚ˆã‚‹ç”»åƒç”Ÿæˆ

#### 9:16ç¸¦é•·ç”»åƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

YouTube Shortsã‚„TikTokã¯ç¸¦å‹å‹•ç”»ï¼ˆ9:16ï¼‰ãªã®ã§ã€ç”»åƒã‚‚ç¸¦é•·ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
from openai import AzureOpenAI

def generate_image(
    summary: str,
    output_path: str,
    config: Config
) -> str:
    """DALL-E 3ã§ç¸¦é•·ç”»åƒã‚’ç”Ÿæˆ"""

    client = AzureOpenAI(
        api_version=config.azure_openai_api_version,
        azure_endpoint=config.azure_openai_endpoint,
        api_key=config.azure_openai_api_key
    )

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    image_prompt = f"""Create a cinematic concept art image representing this news:
{summary[:200]}

Style: Photorealistic, dramatic lighting, wide landscape shot
Mood: Professional, engaging, modern
Aspect: Vertical format suitable for mobile viewing
"""

    # DALL-E 3å‘¼ã³å‡ºã—
    response = client.images.generate(
        model=config.azure_openai_image_deployment,
        prompt=image_prompt,
        size="1024x1792",  # 9:16ã®ç¸¦é•·
        quality="standard",  # or "hd"
        n=1
    )

    # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨ä¿å­˜
    image_data = response.data[0]

    if image_data.url:
        # URLã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        import requests
        img_response = requests.get(image_data.url)
        with open(output_path, "wb") as f:
            f.write(img_response.content)
    elif image_data.b64_json:
        # Base64ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        import base64
        img_bytes = base64.b64decode(image_data.b64_json)
        with open(output_path, "wb") as f:
            f.write(img_bytes)
    else:
        raise Exception("No image data returned from DALL-E 3")

    print(f"âœ“ Image generated: {output_path}")
    return output_path
```

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚³ãƒ„ï¼š**

1. **"Cinematic concept art":** å†™çœŸã‚ˆã‚Šã‚‚ã‚¢ãƒ¼ãƒˆçš„ãªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ç”Ÿæˆ
2. **"Vertical format":** ç¸¦å‹ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ç¤º
3. **è¦ç´„ã®å†’é ­200æ–‡å­—ã®ã¿ä½¿ç”¨:** å…¨æ–‡ã‚’å…¥ã‚Œã‚‹ã¨ç”»åƒã®ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ãŒã¼ã‚„ã‘ã‚‹

**ã‚µã‚¤ã‚ºã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼š**

DALL-E 3ã§ã¯ä»¥ä¸‹ã®ã‚µã‚¤ã‚ºãŒé¸æŠå¯èƒ½ï¼š
- `1024x1024`ï¼ˆæ­£æ–¹å½¢ï¼‰
- `1024x1792`ï¼ˆç¸¦é•·ï¼‰â† **ä»Šå›ä½¿ç”¨**
- `1792x1024`ï¼ˆæ¨ªé•·ï¼‰

#### base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã¨URLå–å¾—ã®ä¸¡å¯¾å¿œ

DALL-E 3ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã€ç’°å¢ƒã«ã‚ˆã£ã¦**URLå½¢å¼**ã¨**base64å½¢å¼**ã®2ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚

**å®‰å…¨ãªå®Ÿè£…ï¼š**

```python
def save_image_from_response(response_data, output_path: str):
    """DALL-E 3ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç”»åƒã‚’ä¿å­˜ï¼ˆä¸¡å½¢å¼å¯¾å¿œï¼‰"""
    if response_data.url:
        # URLå½¢å¼
        import requests
        img = requests.get(response_data.url)
        img.raise_for_status()  # ã‚¨ãƒ©ãƒ¼æ™‚ã«ä¾‹å¤–ã‚’ç™ºç”Ÿ
        with open(output_path, "wb") as f:
            f.write(img.content)

    elif response_data.b64_json:
        # Base64å½¢å¼
        import base64
        img_bytes = base64.b64decode(response_data.b64_json)
        with open(output_path, "wb") as f:
            f.write(img_bytes)

    else:
        raise ValueError("No valid image data in response")
```

#### ç”Ÿæˆå¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯

DALL-E 3ã¯ç¨€ã«ã€Œã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒªã‚·ãƒ¼é•åã€ã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

```python
import time

def generate_image_with_retry(
    summary: str,
    output_path: str,
    config: Config,
    max_retries: int = 3
) -> str:
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãç”»åƒç”Ÿæˆ"""

    for attempt in range(max_retries):
        try:
            return generate_image(summary, output_path, config)

        except Exception as e:
            if "content_policy_violation" in str(e):
                print(f"âš ï¸  Content policy violation, retrying with modified prompt...")
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŠ½è±¡åŒ–ã—ã¦å†è©¦è¡Œ
                summary = "A professional news concept art image"

            elif attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                print(f"âš ï¸  Retry {attempt + 1}/{max_retries} after {wait_time}s...")
                time.sleep(wait_time)
            else:
                raise
```

### ã‚³ã‚¹ãƒˆç®¡ç†ã®Tips

**ç¾åœ¨ã®Azure OpenAIæ–™é‡‘ï¼ˆ2026å¹´2æœˆæ™‚ç‚¹ï¼‰ï¼š**

| ã‚µãƒ¼ãƒ“ã‚¹ | æ–™é‡‘ | 1æœ¬ã‚ãŸã‚Šã‚³ã‚¹ãƒˆï¼ˆ3è¨˜äº‹æƒ³å®šï¼‰ |
|---------|------|------------------------------|
| GPT-4o (è¦ç´„) | $0.005/1Kãƒˆãƒ¼ã‚¯ãƒ³ | ç´„$0.03 |
| DALL-E 3 (standard) | $0.04/æš | $0.12 |
| Speech (æ¨™æº–) | $16/100ä¸‡æ–‡å­— | ç´„$0.008 |
| **åˆè¨ˆ** | - | **ç´„$0.16/æœ¬** |

**æœˆé–“ã‚³ã‚¹ãƒˆè©¦ç®—ï¼š**
- æ¯æ—¥1æœ¬æŠ•ç¨¿ï¼š$4.80/æœˆ
- é€±3æœ¬æŠ•ç¨¿ï¼š$2.06/æœˆ

**ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ã‚¢ã‚¤ãƒ‡ã‚¢ï¼š**
1. ç”»åƒç”Ÿæˆã‚’`quality="standard"`ã«ã™ã‚‹ï¼ˆHDã¯$0.08/æšï¼‰
2. è¤‡æ•°è¨˜äº‹ã§åŒã˜ç”»åƒã‚’ä½¿ã„å›ã™
3. Speech SDKã®Free tierã‚’æ´»ç”¨ï¼ˆæœˆ50ä¸‡æ–‡å­—ã¾ã§ç„¡æ–™ï¼‰

---

ã“ã“ã¾ã§ã§è¨˜äº‹ã®ç´„50%å®Œæˆã§ã™ã€‚ç¶šãã‚’ç”Ÿæˆã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿãã‚Œã¨ã‚‚ã€ã“ã“ã¾ã§ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä¿®æ­£ãƒ»è¿½åŠ ã—ãŸã„éƒ¨åˆ†ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
