import base64
import json
import os
import random
import re
from datetime import datetime
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from moviepy.video.VideoClip import ImageClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.audio.AudioClip import concatenate_audioclips
from moviepy.video.compositing.CompositeVideoClip import concatenate_videoclips
from moviepy.video.fx.Resize import Resize
from moviepy.video.io.VideoFileClip import VideoFileClip
from config import Config
from state import AgentState


def _log_node_output(run_dir: str, node_name: str, payload: dict):
    """å„ãƒãƒ¼ãƒ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’JSONè¡Œã¨ã—ã¦ç¾åœ¨ã®å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸è¿½è¨˜ã™ã‚‹ã€‚"""
    os.makedirs(run_dir, exist_ok=True)
    log_path = os.path.join(run_dir, "node_logs.jsonl")
    entry = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "node": node_name,
        "payload": payload
    }
    with open(log_path, "a", encoding="utf-8") as log_file:
        json.dump(entry, log_file, ensure_ascii=False)
        log_file.write("\n")


def _extract_title_from_content(raw_content: str, fallback: str) -> str:
    """Markdownæœ¬æ–‡ã§æœ€åˆã®éç©ºè¡Œã‚’è¦‹å‡ºã—ã¨ã—ã¦å–å¾—ã—ã€äººãŒèª­ã‚ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿”ã™ã€‚"""
    for line in raw_content.splitlines():
        candidate = line.strip().lstrip("#").strip()
        if candidate:
            return candidate[:120]
    return fallback


text_client = AzureOpenAI(
    api_key=Config.AZURE_TEXT_API_KEY,
    api_version=Config.AZURE_TEXT_API_VERSION,
    azure_endpoint=Config.AZURE_TEXT_ENDPOINT,
    azure_deployment=Config.AZURE_OPENAI_DEPLOYMENT_NAME,
)

image_client = AzureOpenAI(
    api_key=Config.AZURE_IMAGE_API_KEY,
    api_version=Config.AZURE_IMAGE_API_VERSION,
    azure_endpoint=Config.AZURE_IMAGE_ENDPOINT,
    azure_deployment=Config.AZURE_IMAGE_DEVELOPMENT_NAME,
)

VIDEO_EXTENSIONS = (".mp4", ".mov", ".m4v", ".avi", ".webm", ".mkv")


def _list_movie_files() -> list[str]:
    """è¨­å®šæ¸ˆã¿ã®movieãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªèƒŒæ™¯å‹•ç”»ã‚’åé›†ã™ã‚‹ã€‚"""
    movie_dir = Config.MOVIE_DIR
    if not movie_dir or not os.path.isdir(movie_dir):
        return []
    files = []
    for name in os.listdir(movie_dir):
        if name.lower().endswith(VIDEO_EXTENSIONS):
            files.append(os.path.join(movie_dir, name))
    return files


def _format_date_label(date_str: str) -> str:
    """YYYYMMDDå½¢å¼ã‚’è¡¨ç¤ºç”¨ã®YYYY/MM/DDè¡¨è¨˜ã¸å¤‰æ›ã™ã‚‹ã€‚"""
    try:
        return datetime.strptime(date_str, "%Y%m%d").strftime("%Y/%m/%d")
    except ValueError:
        return date_str


def _format_date_range_label(start: str, end: str) -> str:
    """äººãŒè¦‹ã¦åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥ä»˜ãƒ¬ãƒ³ã‚¸è¡¨ç¾ã‚’ä½œæˆã™ã‚‹ã€‚"""
    start_label = _format_date_label(start)
    end_label = _format_date_label(end)
    return start_label if start == end else f"{start_label} - {end_label}"


def _clean_hashtag_text(text: str) -> str:
    """YouTubeã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¨ã—ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ã€‚"""
    cleaned = re.sub(r"[#ï¼ƒ]", "", text)
    cleaned = re.sub(r"\s+", "", cleaned)
    cleaned = re.sub(r"[^\wã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯ãƒ¼]+", "", cleaned)
    return cleaned[:20].strip()


def _extract_hashtags(articles: list[dict]) -> list[str]:
    """è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ´¾ç”Ÿã•ã›ãŸãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®çŸ­ã„ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    hashtags: list[str] = []
    for article in articles:
        candidate = article.get('display_title') or article.get('title')
        if not candidate:
            continue
        cleaned = _clean_hashtag_text(candidate)
        if not cleaned or cleaned in hashtags:
            continue
        hashtags.append(cleaned)
        if len(hashtags) >= 5:
            break

    for fallback in ("ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»", "AIé€Ÿå ±"):
        if len(hashtags) >= 5:
            break
        if fallback not in hashtags:
            hashtags.append(fallback)

    return hashtags[:5]


def _generate_youtube_metadata(state: AgentState) -> dict:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹ã‹ã‚‰YouTubeå‘ã‘ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜æ–‡ãƒ»ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚"""
    articles = state.get('articles', [])
    range_label = _format_date_range_label(
        state['start_date'], state['end_date'])

    if articles:
        title = f"{range_label}ã®ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹TOP{len(articles)} | ã‚·ãƒ§ãƒ¼ãƒˆè§£èª¬"
        if len(articles) == 1:
            title = f"{range_label} {articles[0]['title'] } | ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚·ãƒ§ãƒ¼ãƒˆ"
    else:
        title = f"{range_label}ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ"

    description_lines = [
        f"ğŸ“… åéŒ²æœŸé–“: {range_label}",
        "",
        "ğŸ“ å–ã‚Šä¸Šã’ãŸãƒˆãƒ”ãƒƒã‚¯:"
    ]
    if articles:
        for article in articles:
            description_lines.append(
                f"- {article.get('display_title') or article['title']} ({_format_date_label(article.get('date', state['start_date']))})"
            )
    else:
        description_lines.append("- è©²å½“ã™ã‚‹è¨˜äº‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    description = "\n".join(description_lines).strip()
    hashtags = _extract_hashtags(articles)
    if articles:
        primary = articles[0]
        base_thumb = primary.get('display_title') or primary.get('title') or ""
    else:
        base_thumb = ""
    if base_thumb:
        thumbnail_title = base_thumb[:40]
    else:
        thumbnail_title = title[:40] if title else "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"

    return {
        "title": title,
        "description": description,
        "hashtags": hashtags,
        "thumbnail_title": thumbnail_title
    }


def _format_timestamp(seconds: float) -> str:
    """SBVå½¢å¼ï¼ˆH:MM:SS.mmmï¼‰ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    milliseconds = max(0, int(round(seconds * 1000)))
    hours, remainder = divmod(milliseconds, 3600 * 1000)
    minutes, remainder = divmod(remainder, 60 * 1000)
    secs, millis = divmod(remainder, 1000)
    return f"{hours}:{minutes:02}:{secs:02}.{millis:03}"


def _split_sentences_for_captions(text: str) -> list[str]:
    """ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ–‡ç« ã‚’SBVãƒ•ã‚¡ã‚¤ãƒ«ã«é©ã—ãŸç²’åº¦ã¸åˆ†å‰²ã™ã‚‹ã€‚"""
    if not text:
        return []

    stripped = text.strip()
    if not stripped:
        return []

    # ã€Œã€‚ã€ã§ã®ã¿åŒºåˆ‡ã‚Šã€å¥èª­ç‚¹ã‚’ç¶­æŒã—ãŸã¾ã¾æŠ½å‡º
    sentences = [
        chunk.strip()
        for chunk in re.findall(r'[^ã€‚]+ã€‚?', stripped)
        if chunk.strip()
    ]

    return sentences or [stripped]


def _build_sbv_caption(text: str, duration: float | None) -> str:
    """æ–‡ç« ã¨æƒ³å®šå°ºã‹ã‚‰ç–‘ä¼¼ã‚¿ã‚¤ãƒŸãƒ³ã‚°ä»˜ãSBVå­—å¹•ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    sentences = _split_sentences_for_captions(text)
    if not sentences:
        sentences = ["ï¼ˆå†…å®¹ãªã—ï¼‰"]

    total_chars = sum(len(s) for s in sentences) or 1
    total_duration = duration if duration and duration > 0 else len(
        sentences) * 3.0

    raw_durations = []
    for sentence in sentences:
        portion = max(0.8, (len(sentence) / total_chars) * total_duration)
        raw_durations.append(portion)

    scale = total_duration / \
        sum(raw_durations) if sum(raw_durations) > 0 else 1.0
    durations = [d * scale for d in raw_durations]

    lines = []
    cursor = 0.0
    for sentence, seg_duration in zip(sentences, durations):
        start_ts = _format_timestamp(cursor)
        end_ts = _format_timestamp(cursor + seg_duration)
        lines.append(f"{start_ts},{end_ts}")
        lines.append(sentence)
        lines.append("")
        cursor += seg_duration

    return "\n".join(lines).strip() + "\n"


def fetch_articles_node(state: AgentState):
    """æ—¥ä»˜ãƒ¬ãƒ³ã‚¸å†…ã®Markdownè¨˜äº‹ã‚’èª­ã¿è¾¼ã¿ã€ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«è¦ç´„ã™ã‚‹ã€‚"""
    target_articles = []
    # ãƒ•ã‚£ãƒ«ã‚¿è¨ˆç®—ã«å‚™ãˆã¦æ—¥æ™‚ã«å¤‰æ›ã—ã¦ãŠã
    start = datetime.strptime(state['start_date'], "%Y%m%d")
    end = datetime.strptime(state['end_date'], "%Y%m%d")
    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR

    single_article_path = state.get("single_article_path")

    if not single_article_path and not os.path.exists(Config.ARTICLE_DIR):
        os.makedirs(Config.ARTICLE_DIR)

    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå˜ä¸€æŒ‡å®šã‹æ—¥ä»˜ãƒ¬ãƒ³ã‚¸ã‹ã§åˆ†å²ï¼‰
    files_to_process: list[tuple[str, str, str]] = []
    if single_article_path:
        if not os.path.isfile(single_article_path):
            raise FileNotFoundError(f"è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {single_article_path}")
        basename = os.path.basename(single_article_path)
        match = re.match(r"(\d{8})_(.*)\.md", basename)
        if match:
            file_date_str, title = match.groups()
        else:
            file_date_str = state['start_date']
            title = os.path.splitext(basename)[0]
        files_to_process.append((single_article_path, title, file_date_str))
    else:
        for filename in os.listdir(Config.ARTICLE_DIR):
            match = re.match(r"(\d{8})_(.*)\.md", filename)
            if match:
                file_date_str, title = match.groups()
                file_date = datetime.strptime(file_date_str, "%Y%m%d")
                if start <= file_date <= end:
                    files_to_process.append(
                        (os.path.join(Config.ARTICLE_DIR, filename), title, file_date_str))

    # 2. å„è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã¨è¦ç´„ï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ä½œæˆï¼‰
    for filepath, title, date_str in files_to_process:
        with open(filepath, 'r', encoding='utf-8') as f:
            raw_content = f.read()

        # GPT-4oã«ã‚ˆã‚‹è¦ç´„ã¨ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•´å½¢
        # ã“ã“ã§URLã®é™¤å»ã‚„è‡ªç„¶ãªè¨€ã„å›ã—ã¸ã®å¤‰æ›ã‚’æŒ‡ç¤º
        response = text_client.chat.completions.create(
            model=Config.AZURE_OPENAI_DEPLOYMENT_NAME,  # GPT-4oç”¨ãƒ‡ãƒ—ãƒ­ã‚¤å
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ã§ã™ã€‚"},
                {"role": "user", "content": f"""
ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ã€YouTubeã‚·ãƒ§ãƒ¼ãƒˆç”¨ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã€åˆ¶ç´„äº‹é …ã€‘
ãƒ»500æ–‡å­—ä»¥å†…
ãƒ»å†’é ­ã§æ ¸å¿ƒã‚’ä¼ãˆã‚‹ï¼šã€Œä½•ãŒèµ·ããŸã®ã‹ã€ã€Œãªãœé‡è¦ãªã®ã‹ã€ã‚’æœ€åˆã«æ˜ç¤º
ãƒ»ãã®å¾Œã€æ™‚ç³»åˆ—ã‚„å› æœé–¢ä¿‚ã«æ²¿ã£ã¦èƒŒæ™¯ãƒ»çµŒç·¯ãƒ»å½±éŸ¿ã‚’ç°¡æ½”ã«èª¬æ˜
ãƒ»URLã‚„è¨˜å·ï¼ˆ[ ]ã€( )ãªã©ï¼‰ã¯å®Œå…¨ã«å‰Šé™¤ã¾ãŸã¯è‡ªç„¶ãªè¨€è‘‰ã«ç½®ãæ›ãˆã‚‹
ãƒ»å°‚é–€ç”¨èªã¯ä½¿ç”¨å¯ï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³å‘ã‘ï¼‰ã ãŒã€å¿…è¦ã«å¿œã˜ã¦ç°¡æ½”ãªè£œè¶³ã‚’å…¥ã‚Œã‚‹
ãƒ»ã§ã™ãƒ»ã¾ã™èª¿ã§çµ±ä¸€ã—ã€é å›ã—ãªè¡¨ç¾ã¯é¿ã‘ã‚‹
ãƒ»ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ã‚„å®Ÿå‹™çš„ãªæ„å‘³ã‚’å„ªå…ˆçš„ã«å«ã‚ã‚‹

è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {title}
è¨˜äº‹å†…å®¹:
{raw_content}
"""}
            ]
        )

        summarized_content = response.choices[0].message.content.strip()
        human_title = _extract_title_from_content(
            raw_content, title.replace("_", " "))

        target_articles.append({
            'title': title,
            'display_title': human_title,
            'content': summarized_content,  # ã“ã“ã«ç¶ºéº—ãªè¦ç´„ãŒå…¥ã‚‹
            'date': date_str
        })
        print(f"âœ… è¦ç´„å®Œäº†: {title}")

    _log_node_output(
        run_dir,
        "fetch_articles",
        {
            "article_count": len(target_articles),
            "article_titles": [article['display_title'] for article in target_articles],
            "articles": target_articles
        }
    )

    return {'articles': target_articles, 'run_output_dir': run_dir}


def generate_audio_assets_node(state: AgentState):
    """å„è¨˜äº‹ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã¨å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    audio_paths = []
    script_paths = []
    voice_outputs = []

    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)

    for i, article in enumerate(state['articles']):
        # éŸ³å£°åˆæˆã®è¨­å®šã‚’è¨˜äº‹ã”ã¨ã«åˆæœŸåŒ–ï¼ˆ1æœ¬ãšã¤åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ï¼‰
        # å„è¨˜äº‹ã”ã¨ã« Azure Speech ã‚’è¨­å®šï¼ˆéŸ³å£°ã‚¹ã‚¿ã‚¤ãƒ«ã‚’çµ±ä¸€ï¼‰
        speech_config = speechsdk.SpeechConfig(
            subscription=Config.AZURE_SPEECH_KEY,
            region=Config.AZURE_SPEECH_REGION
        )
        speech_config.speech_synthesis_voice_name = "ja-JP-NanamiNeural"

        audio_filename = f"audio_{i}.wav"
        audio_path = os.path.join(run_dir, audio_filename)
        audio_config = speechsdk.audio.AudioOutputConfig(filename=audio_path)

        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’éŸ³å£°åŒ–ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜
        synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=speech_config, audio_config=audio_config)
        synthesizer.speak_text_async(article['content']).get()
        audio_paths.append(audio_path)

        # å­—å¹•ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨ˆç®—ç”¨ã«é•·ã•ã‚’å–å¾—ï¼ˆå¤±æ•—ã—ã¦ã‚‚ç„¡è¦–ï¼‰
        audio_duration = None
        try:
            temp_clip = AudioFileClip(audio_path)
            audio_duration = temp_clip.duration or None
        except Exception:
            audio_duration = None
        finally:
            try:
                temp_clip.close()
            except Exception:
                pass

        script_filename = f"script_{i}.sbv"
        script_path = os.path.join(run_dir, script_filename)
        # SBV å½¢å¼ã®å­—å¹•ã‚’ç”Ÿæˆã—ã€YouTubeã§ç›´æ¥ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
        captions_content = _build_sbv_caption(
            article['content'], audio_duration)
        with open(script_path, "w", encoding="utf-8") as script_file:
            script_file.write(captions_content)
        script_paths.append(script_path)

        voice_outputs.append({
            "index": i,
            "article_title": article.get('display_title') or article['title'],
            "audio_path": audio_path,
            "script_path": script_path,
            "spoken_text": article['content']
        })

    _log_node_output(
        run_dir,
        "generate_audio_assets",
        {
            "audio_files": [os.path.basename(p) for p in audio_paths],
            "script_files": [os.path.basename(p) for p in script_paths],
            "voice_outputs": [
                {
                    "index": entry["index"],
                    "article_title": entry["article_title"],
                    "spoken_text": entry["spoken_text"],
                    "audio_file": os.path.basename(entry["audio_path"]),
                    "script_file": os.path.basename(entry["script_path"])
                }
                for entry in voice_outputs
            ]
        }
    )

    return {
        'audio_paths': audio_paths,
        'script_paths': script_paths,
        'run_output_dir': run_dir
    }


def generate_visual_assets_node(state: AgentState):
    """è¨˜äº‹ã”ã¨ã«è§£èª¬ç”¨ã‚¤ãƒ©ã‚¹ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    image_paths = []
    image_prompts = []
    image_outputs = []

    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)

    for i, article in enumerate(state['articles']):
        # ã¾ãšã¯è¨˜äº‹å†…å®¹ã‹ã‚‰è‹±èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æ–¹é‡ã‚’æ±ºã‚ã‚‹
        # GPT ã«æ˜ ç”»çš„ãªé¢¨æ™¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œã‚‰ã›ã‚‹ï¼ˆFLUXç”¨ï¼‰
        prompt_response = text_client.chat.completions.create(
            model=Config.AZURE_OPENAI_DEPLOYMENT_NAME,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ã‚ãªãŸã¯å ±é“ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’èª­ã¿ã€"
                        "ãã®å†…å®¹ã‚’è¦–è¦šçš„ã«ä¼ãˆã‚‹ç”»åƒç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‹±èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"

                        "ã€å¿…é ˆè¦ç´ ã€‘\n"
                        "ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ ¸å¿ƒçš„ãªã€Œãƒ¢ãƒã€ã€Œå ´æ‰€ã€ã€ŒçŠ¶æ³ã€ã‚’å…·ä½“çš„ã«æå†™\n"
                        "ãƒ»æŠ€è¡“ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šè£½å“ã€ãƒ‡ãƒã‚¤ã‚¹ã€ã‚¤ãƒ³ãƒ•ãƒ©ã€ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n"
                        "ãƒ»ãƒ“ã‚¸ãƒã‚¹ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šã‚ªãƒ•ã‚£ã‚¹ç©ºé–“ã€éƒ½å¸‚æ™¯è¦³ã€ä¼æ¥­ãƒ­ã‚´ã®ãªã„ãƒ“ãƒ«ç¾¤\n"
                        "ãƒ»æ”¿ç­–ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šè­°å ´ã€å…¬å…±æ–½è¨­ã€è±¡å¾´çš„ãªå»ºé€ ç‰©\n"
                        "ãƒ»ç’°å¢ƒç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼šè‡ªç„¶ç’°å¢ƒã€æ°—å€™ç¾è±¡ã€ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ \n\n"

                        "ã€ç¦æ­¢äº‹é …ã€‘\n"
                        "ãƒ»å®Ÿåœ¨ã®äººç‰©ã®é¡”ã‚„ä½“ï¼ˆå¾Œã‚å§¿ã‚„é æ™¯ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã¯å¯ï¼‰\n"
                        "ãƒ»å®Ÿåœ¨ä¼æ¥­ã®ãƒ­ã‚´ã‚„å•†æ¨™\n"
                        "ãƒ»ç‰¹å®šå¯èƒ½ãªå€‹äººãŒå†™ã‚Šè¾¼ã‚€æ§‹å›³\n\n"

                        "ã€æ¨å¥¨è¡¨ç¾ã€‘\n"
                        "ãƒ»æŠ½è±¡çš„ãªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ï¼ˆä¾‹ï¼šAIãƒ‹ãƒ¥ãƒ¼ã‚¹â†’è„³ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¨¡æ§˜ï¼‰\n"
                        "ãƒ»è±¡å¾´çš„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆä¾‹ï¼šåŠå°ä½“ãƒ‹ãƒ¥ãƒ¼ã‚¹â†’ãƒã‚¤ã‚¯ãƒ­ãƒãƒƒãƒ—ã®ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—ï¼‰\n"
                        "ãƒ»ç’°å¢ƒã‚„ç©ºé–“ã§çŠ¶æ³ã‚’è¡¨ç¾ï¼ˆä¾‹ï¼šçµŒæ¸ˆå±æ©Ÿâ†’ç„¡äººã®ã‚ªãƒ•ã‚£ã‚¹ãƒ•ãƒ­ã‚¢ï¼‰\n\n"

                        "ã€ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡å®šã€‘\n"
                        "ãƒ»9:16ç¸¦å‹æ§‹å›³ã‚’æ„è­˜\n"
                        "ãƒ»ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¸ãƒ£ãƒ¼ãƒŠãƒªã‚ºãƒ é¢¨ã®å†™å®Ÿçš„ã‚¹ã‚¿ã‚¤ãƒ«\n"
                        "ãƒ»è‰²å½©ã¯è¨˜äº‹ã®ãƒˆãƒ¼ãƒ³ï¼ˆå¸Œæœ›çš„/è­¦å‘Šçš„/ä¸­ç«‹çš„ï¼‰ã«åˆã‚ã›ã‚‹\n"
                        "ãƒ»è¦–èªæ€§ã®é«˜ã„æ˜ç­ãªæ§‹å›³"
                    )
                },
                {
                    "role": "user",
                    "content": f"è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {article.get('display_title') or article['title']}\nè¨˜äº‹å†…å®¹: {article['content']}"
                }
            ]
        )
        img_prompt = prompt_response.choices[0].message.content.strip()
        image_prompts.append(img_prompt)

        # 9:16 æ¯”ç‡ã®ã‚¤ãƒ©ã‚¹ãƒˆã‚’æç”»ã—ã€å‹•ç”»å†’é ­ã®é™æ­¢ç”»ã«ä½¿ç”¨
        image_result = image_client.images.generate(
            model=Config.AZURE_IMAGE_DEVELOPMENT_NAME,
            prompt=f"{img_prompt} Digital art style, vibrant colors, 9:16 aspect ratio focus.",
            size="1792x1024",
            n=1,
            response_format="b64_json",
        )

        image_data = image_result.data[0]
        image_location = None
        if image_data.url:
            image_location = image_data.url
            image_paths.append(image_location)
        else:
            image_filename = f"image_{i}.png"
            image_path = os.path.join(run_dir, image_filename)
            with open(image_path, "wb") as img_file:
                img_file.write(base64.b64decode(image_data.b64_json))
            image_location = image_path
            image_paths.append(image_location)

        image_outputs.append({
            "index": i,
            "article_title": article.get('display_title') or article['title'],
            "prompt": img_prompt,
            "image_path": image_location
        })

    _log_node_output(
        run_dir,
        "generate_visual_assets",
        {
            "image_files": [os.path.basename(p) if p else None for p in image_paths],
            "image_prompts": image_prompts,
            "image_outputs": [
                {
                    "index": entry["index"],
                    "article_title": entry["article_title"],
                    "prompt": entry["prompt"],
                    "image_file": os.path.basename(entry["image_path"]) if entry["image_path"] else None
                }
                for entry in image_outputs
            ]
        }
    )

    return {
        'image_paths': image_paths,
        'run_output_dir': run_dir
    }


def create_short_video_node(state: AgentState):
    """ç”Ÿæˆæ¸ˆã¿ã®é™æ­¢ç”»ãƒ»ã‚¹ãƒˆãƒƒã‚¯æ˜ åƒãƒ»ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã‚’çµåˆã—çŸ­å°ºå‹•ç”»ã‚’ä½œã‚‹ã€‚"""
    clips = []
    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)
    output_path = os.path.join(run_dir, "final_youtube_short.mp4")
    movie_files = _list_movie_files()
    video_sources: list[VideoFileClip] = []
    article_visual_logs = []
    article_audio_clips: list[AudioFileClip] = []
    audio_timeline = []
    audio_cursor = 0.0

    for i, article in enumerate(state['articles']):
        # è¨˜äº‹ã”ã¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ 1 ã‚¯ãƒªãƒƒãƒ—ã«ã¾ã¨ã‚ã‚‹
        audio = AudioFileClip(state['audio_paths'][i])
        article_audio_clips.append(audio)
        duration = audio.duration or 0
        duration = max(duration, 0.001)

        base_image = ImageClip(state['image_paths'][i], duration=duration)
        base_image = base_image.with_effects([Resize(height=1920)])

        def zoom_factor(t, total=duration):
            return 1 + 0.05 * (t / max(total, 0.001))

        base_image = base_image.with_effects([Resize(new_size=zoom_factor)])
        base_image = base_image.with_position("center")

        segments = []
        movie_segments_log = []

        image_intro_duration = min(5, duration)
        segments.append(base_image.with_duration(image_intro_duration))
        remaining = duration - image_intro_duration

        while remaining > 1e-3 and movie_files:
            # ã‚¹ãƒˆãƒƒã‚¯æ˜ åƒã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å·®ã—è¾¼ã¿ã€é™æ­¢ç”»ã ã‘ã®å˜èª¿ã•ã‚’æŠ‘ãˆã‚‹
            movie_path = random.choice(movie_files)
            try:
                video_clip = VideoFileClip(movie_path)
                video_sources.append(video_clip)
            except Exception:
                continue

            clip_duration = min(5, remaining, video_clip.duration or 0)
            if clip_duration <= 0:
                video_clip.close()
                continue

            max_start = max(
                0, (video_clip.duration or clip_duration) - clip_duration)
            start = random.uniform(0, max_start) if max_start > 0 else 0

            segment = video_clip.subclipped(
                start_time=start,
                end_time=start + clip_duration
            ).with_audio(None)

            segment = segment.with_effects(
                [Resize(height=1920)]).with_position("center")
            segments.append(segment)

            movie_segments_log.append({
                "file": os.path.basename(movie_path),
                "start": round(start, 2),
                "duration": round(clip_duration, 2)
            })

            remaining -= clip_duration

        if remaining > 1e-3:
            segments.append(base_image.with_duration(remaining))

        # é™æ­¢ç”»ã¨å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆã—ã€è¨˜äº‹ã”ã¨ã®ã‚·ãƒ§ãƒ¼ãƒˆã‚¯ãƒªãƒƒãƒ—ã‚’å®Œæˆã•ã›ã‚‹
        article_video = concatenate_videoclips(
            segments, method="compose").with_duration(duration)
        article_video.audio = audio
        clips.append(article_video)

        article_visual_logs.append({
            "article": article.get('display_title') or article['title'],
            "movie_segments": movie_segments_log
        })

        audio_timeline.append({
            "article": article.get('display_title') or article['title'],
            "audio_file": os.path.basename(state['audio_paths'][i]),
            "start": round(audio_cursor, 2),
            "duration": round(duration, 2)
        })
        audio_cursor += duration

    final_video = concatenate_videoclips(clips, method="compose")
    final_audio = None
    if article_audio_clips:
        final_audio = concatenate_audioclips(article_audio_clips)
        final_video.audio = final_audio

    try:
        final_video.write_videofile(
            output_path, fps=24, codec="libx264", audio_codec="aac"
        )
    finally:
        final_video.close()
        if final_audio is not None:
            try:
                final_audio.close()
            except Exception:
                pass
        for audio_clip in article_audio_clips:
            try:
                audio_clip.close()
            except Exception:
                pass
        for source in video_sources:
            try:
                source.close()
            except Exception:
                pass

    _log_node_output(
        run_dir,
        "create_video",
        {
            "video_file": os.path.basename(output_path),
            "clip_count": len(clips),
            "articles": article_visual_logs,
            "audio_timeline": audio_timeline
        }
    )

    return {
        "video_path": output_path,
        'run_output_dir': run_dir
    }


def generate_youtube_metadata_node(state: AgentState):
    """YouTubeæŠ•ç¨¿ç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜æ–‡ãƒ»ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’æ•´å‚™ã™ã‚‹ã€‚"""
    run_dir = state.get('run_output_dir') or Config.OUTPUT_DIR
    os.makedirs(run_dir, exist_ok=True)

    metadata = _generate_youtube_metadata(state)
    hashtags_line = " ".join(f"#{tag}" for tag in metadata['hashtags']).strip()
    metadata_path = os.path.join(run_dir, "youtube_meta.txt")

    articles = state.get("articles") or []
    if articles:
        primary_title = articles[0].get(
            'display_title') or articles[0].get('title') or "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    else:
        primary_title = "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    note_line = f"- note: {primary_title}"
    zenn_line = f"- zenn: {primary_title}"

    spoken_block = "\n\n".join(
        article.get('content', '').strip()
        for article in articles if article.get('content')
    ).strip()

    sections = [
        "ã€å†…å®¹ã€‘",
        note_line,
        zenn_line,
        "",
    ]

    if articles:
        for idx, article in enumerate(articles, start=1):
            title = article.get('display_title') or article.get(
                'title') or f"è¨˜äº‹{idx}"
            spoken = article.get('content', '').strip()
            sections.append(f"{idx}. {title}")
            if spoken:
                sections.append(spoken)
            sections.append("")
    elif spoken_block:
        sections.append(spoken_block)
        sections.append("")

    sections.extend([
        "ITç³»ã®æƒ…å ±ã‚’ç™ºä¿¡ã—ã¦ã„ã¾ã™ã€‚",
        "note",
        "https://note.com/kenquichi",
        "zenn",
        "https://zenn.dev/kenquichi",
        "",
        "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹è¬›åº§",
        "https://note.com/kenquichi/m/mc4926a77c1da",
        "",

        "\n".join(f"#{tag}" for tag in metadata['hashtags']) or "#ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    ])

    final_text = "\n".join(sections).rstrip() + "\n"

    with open(metadata_path, "w", encoding="utf-8") as meta_file:
        meta_file.write(final_text)

    _log_node_output(
        run_dir,
        "generate_youtube_metadata",
        {
            "metadata_file": os.path.basename(metadata_path),
            "title": metadata['title'],
            "description": metadata['description'],
            "hashtags": metadata['hashtags'],
            "hashtags_line": hashtags_line or "#ãƒ‹ãƒ¥ãƒ¼ã‚¹ #ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»",
            "thumbnail_file": os.path.basename(state.get('thumbnail_path')) if state.get('thumbnail_path') else None,
            "thumbnail_title": metadata['thumbnail_title']
        }
    )

    return {
        "youtube_metadata_path": metadata_path,
        "thumbnail_title": metadata['thumbnail_title'],
        'run_output_dir': run_dir
    }
